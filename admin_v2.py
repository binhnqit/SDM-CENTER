import streamlit as st
from supabase import create_client, Client
import pandas as pd
from datetime import datetime, timedelta, timezone  # Th√™m timezone v√†o ƒë√¢y
import plotly.express as px
import base64, zlib, time
import streamlit as st

# --- CORE CONFIG FROM SECRETS ---
# Kh√¥ng c√≤n hard-code, b·∫£o m·∫≠t tuy·ªát ƒë·ªëi khi chia s·∫ª code
SUPABASE_URL = st.secrets["supabase"]["url"]
SUPABASE_KEY = st.secrets["supabase"]["key"]
ADMIN_PASSWORD = st.secrets["auth"]["admin_password"]

# C√°c ph·∫ßn kh·ªüi t·∫°o Client gi·ªØ nguy√™n
sb: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

st.set_page_config(page_title="4Oranges SDM Lux Secure Pro", layout="wide", initial_sidebar_state="expanded")

# --- STYLE APPLE CSS ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f7; }
    .stMetric { background-color: white; padding: 20px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
    div[data-baseweb="tab-list"] { gap: 15px; }
    div[data-baseweb="tab"] { padding: 10px 20px; background-color: #e5e5e7 !important; border-radius: 10px 10px 0 0 !important; margin-right: 2px; }
    div[data-baseweb="tab"][aria-selected="true"] { background-color: #0071e3 !important; color: white !important; }
    </style>
""", unsafe_allow_html=True)

# --- LOGIN LOGIC ---
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

if not st.session_state['authenticated']:
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.write(""); st.write("") 
        st.markdown("<div style='text-align: center;'><h1 style='color: #1d1d1f;'>üçäüçäüçäüçä 4Oranges Secure</h1><p style='color: #86868b;'>Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u qu·∫£n tr·ªã</p></div>", unsafe_allow_html=True)
        pwd = st.text_input("", type="password", placeholder="Password", label_visibility="collapsed")
        if st.button("ƒêƒÉng nh·∫≠p", use_container_width=True, type="primary"):
            if pwd == ADMIN_PASSWORD:
                st.session_state['authenticated'] = True
                st.rerun()
            else:
                st.error("M·∫≠t kh·∫©u kh√¥ng ch√≠nh x√°c.")
    st.stop()

# --- AUTO-CLEAN ENGINE (ƒê√£ s·ª≠a ƒë·ªïi ƒë·ªÉ gi·ªØ l·∫°i nh·∫≠t k√Ω) ---
def auto_clean():
    try:
        # S·∫øp mu·ªën gi·ªØ 30 ng√†y? Ch·ªâ c·∫ßn s·ª≠a s·ªë 30 ·ªü ƒë√¢y
        retention_days = 30 
        past_date = (datetime.now() - timedelta(days=retention_days)).strftime("%Y-%m-%d")
        
        # X√≥a c√°c b·∫£n ghi ƒë√£ DONE v√† c≈© h∆°n 30 ng√†y
        sb.table("file_queue").delete().eq("status", "DONE").lt("timestamp", past_date).execute()
    except: 
        pass
def render_import_portal(sb):
    st.markdown("""
        <div style="background-color: #0071e3; padding: 20px; border-radius: 15px; color: white; margin-bottom: 20px;">
            <h2 style="margin:0;">üì• AI Data Port</h2>
            <p style="margin:0; opacity: 0.8;">H·ªá th·ªëng n·∫°p d·ªØ li·ªáu l·ªãch s·ª≠ pha m√†u (DispenseHistory.csv)</p>
        </div>
    """, unsafe_allow_html=True)

    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.info("üí° **H∆∞·ªõng d·∫´n:** Xu·∫•t file .csv t·ª´ ph·∫ßn m·ªÅm pha m√†u v√† t·∫£i l√™n ƒë√¢y ƒë·ªÉ AI ph√¢n t√≠ch s·∫£n l∆∞·ª£ng v√† l·ªói k·ªπ thu·∫≠t.")
        # L·∫•y danh s√°ch m√°y ƒë·ªÉ g√°n d·ªØ li·ªáu
        res_dev = sb.table("devices").select("machine_id").execute()
        list_machines = [d['machine_id'] for d in res_dev.data] if res_dev.data else ["Unknown"]
        selected_target = st.selectbox("üéØ G√°n d·ªØ li·ªáu cho m√°y:", list_machines)
        
        uploaded_file = st.file_uploader("K√©o th·∫£ file .csv v√†o ƒë√¢y", type=['csv'])

    if uploaded_file is not None:
        try:
            # ƒê·ªçc d·ªØ li·ªáu
            df = pd.read_csv(uploaded_file)
            
            # --- PH√ÇN T√çCH NHANH (PREVIEW) ---
            with c2:
                st.write("üîç **Xem tr∆∞·ªõc d·ªØ li·ªáu:**")
                # T√≠nh t·ªïng th·ª±c t·∫ø t·ª´ c√°c Line Dispensed (Spec c·ªßa s·∫øp)
                line_cols = [c for c in df.columns if 'LINES_DISPENSED_AMOUNT' in c]
                df['ACTUAL_TOTAL'] = df[line_cols].sum(axis=1)
                
                # T√≠nh sai s·ªë
                df['ERROR_GAP'] = (df['WANTED_AMOUNT'] - df['ACTUAL_TOTAL']).abs()
                
                # Hi·ªÉn th·ªã s·ªë li·ªáu t·ªïng quan
                m1, m2, m3 = st.columns(3)
                m1.metric("T·ªïng m·∫ª pha", len(df))
                m2.metric("Doanh s·ªë", f"{df['PRICE'].sum():,.0f} VND")
                m3.metric("Sai s·ªë TB", f"{df['ERROR_GAP'].mean():.4f}")

                st.dataframe(df[['DISPENSED_DATE', 'PRODUCT_NAME', 'COLOR_NAME', 'WANTED_AMOUNT', 'ACTUAL_TOTAL', 'PRICE']].head(10), use_container_width=True)

            # --- N√öT K√çCH HO·∫†T ---
            if st.button("üöÄ X√ÅC NH·∫¨N IMPORT V√ÄO AI CLOUD", use_container_width=True, type="primary"):
                with st.status("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu cho AI Engine..."):
                    # Ch·ªâ l·ªçc l·∫•y c√°c c·ªôt quan tr·ªçng ƒë·ªÉ t·ªëi ∆∞u b·ªô nh·ªõ Supabase
                    import_df = pd.DataFrame({
                        'machine_id': selected_target,
                        'dispensed_date': pd.to_datetime(df['DISPENSED_DATE']).dt.strftime('%Y-%m-%dT%H:%M:%S%z'),
                        'color_name': df['COLOR_NAME'],
                        'product_name': df['PRODUCT_NAME'],
                        'wanted_amount': df['WANTED_AMOUNT'],
                        'actual_amount': df['ACTUAL_TOTAL'],
                        'error_gap': df['ERROR_GAP'],
                        'price': df['PRICE'],
                        'duration_ms': df[[c for c in df.columns if 'DURATION_MILLISECONDS' in c]].sum(axis=1)
                    })
                    
                    # Chuy·ªÉn ƒë·ªïi sang dict ƒë·ªÉ insert
                    data_to_insert = import_df.to_dict(orient='records')
                    
                    # Insert theo l√¥ (tr√°nh qu√° t·∫£i API)
                    batch_size = 100
                    for i in range(0, len(data_to_insert), batch_size):
                        sb.table("color_mix_logs").insert(data_to_insert[i:i+batch_size]).execute()
                
                st.success(f"ƒê√£ n·∫°p th√†nh c√¥ng {len(df)} b·∫£n ghi cho m√°y {selected_target}!")
                st.balloons()
                time.sleep(1)
                st.rerun()

        except Exception as e:
            st.error(f"‚ùå L·ªói ƒë·ªãnh d·∫°ng file: {str(e)}")
            st.warning("Vui l√≤ng ki·ªÉm tra l·∫°i file CSV c√≥ ƒë√∫ng ƒë·ªãnh d·∫°ng c·ªßa m√°y pha m√†u kh√¥ng.")

# --- ƒê·ª´ng qu√™n th√™m g·ªçi h√†m n√†y v√†o tab t∆∞∆°ng ·ª©ng ·ªü ph·∫ßn ƒëi·ªÅu h∆∞·ªõng ch√≠nh ---
# with t_import:
#     render_import_portal(sb)
# --- DATA ENGINE ---
def load_all_data():
    try:
        dev = sb.table("devices").select("*").execute()
        cmd = sb.table("commands").select("*").order("created_at", desc=True).limit(20).execute()
        # L·∫•y file_queue ƒë·ªÉ th·ªëng k√™
        files = sb.table("file_queue").select("*").order("timestamp", desc=True).execute()
        return pd.DataFrame(dev.data), pd.DataFrame(cmd.data), pd.DataFrame(files.data)
    except: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

df_d, df_c, df_f = load_all_data()

# --- HEADER ---
c_head1, c_head2 = st.columns([3, 1])
with c_head1:
    st.title("üçäüçäüçäüçä H·ªÜ TH·ªêNG QU·∫¢N L√ù M√ÅY PHA M√ÄU 4ORANGES - AI")
    st.caption(f"H·ªá th·ªëng v·∫≠n h√†nh th√¥ng minh v4.4 | {datetime.now().strftime('%d/%m/%Y')}")
with c_head2:
    if st.button("ƒêƒÉng xu·∫•t", use_container_width=True):
        st.session_state['authenticated'] = False
        st.rerun()

# --- METRICS ---
if not df_d.empty:
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'])
    now_dt = datetime.now(df_d['last_seen_dt'].dt.tz)
    df_d['is_online'] = (now_dt - df_d['last_seen_dt']) < timedelta(minutes=2)
    online_now = len(df_d[df_d['is_online']])
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("T·ªïng thi·∫øt b·ªã", len(df_d))
    m2.metric("üü¢ Tr·ª±c tuy·∫øn", online_now, delta=f"{online_now/len(df_d)*100:.1f}%")
    m3.metric("T·∫£i CPU TB", f"{df_d['cpu_usage'].mean():.1f}%")
    m4.metric("Dung l∆∞·ª£ng RAM", f"{df_d['ram_usage'].mean():.1f}%")

# --- NAVIGATION TABS ---
# --- TRONG PH·∫¶N KHAI B√ÅO TABS ---
t_mon, t_ctrl, t_file, t_sum, t_offline, t_ai, t_tokens, t_sys = st.tabs([
    "üìä GI√ÅM S√ÅT", "üéÆ ƒêI·ªÄU KHI·ªÇN", "üì§ TRUY·ªÄN FILE", "üìú T·ªîNG K·∫æT", "üïµÔ∏è TRUY V·∫æT", "üß† AI INSIGHT", "üîë QU·∫¢N L√ù TOKEN", "‚öôÔ∏è H·ªÜ TH·ªêNG"
])

# --- N·ªòI DUNG TAB QU·∫¢N L√ù TOKEN ---
with t_tokens:
    st.subheader("üîë Ph√™ duy·ªát thi·∫øt b·ªã m·ªõi (Security Gate)")
    
    # L·∫•y d·ªØ li·ªáu t·ª´ b·∫£ng device_tokens
    res_tokens = sb.table("device_tokens").select("*").execute()
    df_tokens = pd.DataFrame(res_tokens.data)

    if not df_tokens.empty:
        # Hi·ªÉn th·ªã danh s√°ch ch·ªù duy·ªát
        st.write("**Danh s√°ch thi·∫øt b·ªã y√™u c·∫ßu gia nh·∫≠p:**")
        for index, row in df_tokens.iterrows():
            col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
            col1.text(f"ID: {row['machine_id']}")
            col2.text(f"Token: {row['token'][:10]}...")
            
            status = "üü¢ ƒê√£ duy·ªát" if row['is_active'] else "üü° Ch·ªù duy·ªát"
            col3.info(status)
            
            if not row['is_active']:
                if col4.button("PH√ä DUY·ªÜT", key=f"app_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": True}).eq("machine_id", row['machine_id']).execute()
                    st.success(f"ƒê√£ c·∫•p quy·ªÅn cho {row['machine_id']}")
                    time.sleep(1); st.rerun()
            else:
                if col4.button("THU H·ªíI", key=f"rev_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": False}).eq("machine_id", row['machine_id']).execute()
                    st.warning(f"ƒê√£ ng·∫Øt quy·ªÅn {row['machine_id']}")
                    time.sleep(1); st.rerun()
    else:
        st.info("Ch∆∞a c√≥ thi·∫øt b·ªã n√†o g·ª≠i y√™u c·∫ßu Token.")

    # Ph·∫ßn g√°n Token th·ªß c√¥ng (N·∫øu s·∫øp mu·ªën c·∫•p tr∆∞·ªõc cho ƒë·∫°i l√Ω)
    with st.expander("‚ûï C·∫•p Token th·ªß c√¥ng"):
        new_id = st.text_input("Nh·∫≠p Machine ID:")
        new_owner = st.text_input("T√™n ƒë·∫°i l√Ω:")
        if st.button("T·∫†O TOKEN"):
            new_token = base64.b64encode(os.urandom(24)).decode('utf-8')
            sb.table("device_tokens").insert({
                "machine_id": new_id, 
                "token": new_token, 
                "assigned_to": new_owner,
                "is_active": True
            }).execute()
            st.success(f"ƒê√£ c·∫•p Token cho {new_owner}")

with t_mon:
    st.subheader("Tr·∫°ng th√°i thi·∫øt b·ªã th·ªùi gian th·ª±c")
    if not df_d.empty:
        st.dataframe(df_d[['machine_id', 'status', 'cpu_usage', 'ram_usage', 'last_seen', 'agent_version']], use_container_width=True, hide_index=True)

with t_ctrl:
    st.subheader("Trung t√¢m l·ªánh chi·∫øn l∆∞·ª£c")
    selected_machines = st.multiselect("Nh·∫Øm m·ª•c ti√™u:", df_d['machine_id'].tolist() if not df_d.empty else [])
    c_btn1, c_btn2, _ = st.columns([1, 1, 4])
    if c_btn1.button("üîí KH√ìA M√ÅY", use_container_width=True, type="primary"):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "LOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh LOCK ƒë√£ ph√°t ƒëi!")
    if c_btn2.button("üîì M·ªû M√ÅY", use_container_width=True):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "UNLOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh UNLOCK ƒë√£ ph√°t ƒëi!")

with t_file:
    st.subheader("Ph√°t h√†nh b·ªô d·ªØ li·ªáu SDF")
    file_up = st.file_uploader("K√©o th·∫£ file .SDF", type=['sdf'])
    active_machines = df_d['machine_id'].unique().tolist() if not df_d.empty else []
    f_targets = st.multiselect("ƒê·∫°i l√Ω nh·∫≠n m·ª•c ti√™u:", active_machines)
    
    if st.button("üöÄ K√çCH HO·∫†T ƒê·ªíNG B·ªò") and file_up and f_targets:
        with st.status("ƒêang chu·∫©n b·ªã g√≥i tin..."):
            encoded = base64.b64encode(zlib.compress(file_up.getvalue())).decode('utf-8')
            chunks = [encoded[i:i+100000] for i in range(0, len(encoded), 100000)]
            
            for m in f_targets:
                # S·ª¨A L·ªñI 1: Batch_ID ƒë·ªôc nh·∫•t cho m·ªói m√°y ƒë·ªÉ tr√°nh Agent update ch·ªìng ch√©o
                batch_id = f"{m}_{file_up.name}_{int(time.time())}"
                payload = []
                for i, c in enumerate(chunks):
                    payload.append({
                        "machine_id": m, 
                        "file_name": file_up.name, 
                        "data_chunk": c,
                        "part_info": f"PART_{i+1}/{len(chunks)}", 
                        "timestamp": batch_id, # D√πng batch_id l√†m timestamp ƒë·ªãnh danh
                        "status": "PENDING"
                    })
                # Insert theo l√¥ 50 b·∫£n ghi
                for j in range(0, len(payload), 50):
                    sb.table("file_queue").insert(payload[j:j+50]).execute()
            st.success("ƒê√£ ph√°t h√†nh l·ªánh ƒë·ªìng b·ªô!")
            time.sleep(1); st.rerun()

# --- TAB T·ªîNG K·∫æT (S·ª≠a L·ªói Hi·ªÉn Th·ªã) ---
with t_sum:
    st.subheader("üìú Nh·∫≠t k√Ω v·∫≠n h√†nh h·ªá th·ªëng")
    if not df_f.empty:
        # S·ª¨A L·ªñI 2: ∆Øu ti√™n tr·∫°ng th√°i DONE khi Groupby
        # Chuy·ªÉn status v·ªÅ d·∫°ng category ƒë·ªÉ sort: DONE s·∫Ω ƒë·ª©ng tr∆∞·ªõc PENDING
        df_f['status_rank'] = df_f['status'].apply(lambda x: 1 if x == "DONE" else 0)
        
        log_df = (
            df_f.sort_values(by=['status_rank', 'timestamp'], ascending=[False, False])
            .drop_duplicates(subset=['machine_id', 'timestamp']) # timestamp ·ªü ƒë√¢y ch√≠nh l√† batch_id
        )
        
        log_df['Tr·∫°ng th√°i'] = log_df['status'].apply(lambda x: "‚úÖ Ho√†n t·∫•t" if x == "DONE" else "‚è≥ ƒêang nh·∫≠n...")
        
        st.dataframe(
            log_df[['machine_id', 'file_name', 'timestamp', 'Tr·∫°ng th√°i']],
            column_config={
                "machine_id": "M√°y tr·∫°m",
                "file_name": "T√™n File",
                "timestamp": "M√£ Batch (ID)",
                "Tr·∫°ng th√°i": st.column_config.TextColumn("K·∫øt qu·∫£")
            },
            use_container_width=True, hide_index=True
        )
    else:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ truy·ªÅn file.")

with t_offline:
    st.subheader("üïµÔ∏è Ki·ªÉm so√°t v·∫Øng m·∫∑t")
    threshold = st.slider("Ng∆∞·ª°ng v·∫Øng m·∫∑t (ng√†y):", 1, 90, 30)
    if not df_d.empty:
        long_offline = df_d[df_d['last_seen_dt'] < (now_dt - timedelta(days=threshold))]
        st.dataframe(long_offline, use_container_width=True)

import numpy as np # ƒê·∫£m b·∫£o s·∫øp ƒë√£ import th∆∞ vi·ªán n√†y ·ªü ƒë·∫ßu file

# --- TR∆Ø·ªöC H·∫æT: PH·∫¢I C√ì CLASS N√ÄY TH√å TAB AI M·ªöI CH·∫†Y ƒê∆Ø·ª¢C ---
class AI_Engine_v3:
    @staticmethod
    def calculate_features(df_d, now_dt):
        total = len(df_d)
        if total == 0: return None
        
        # ƒê·∫£m b·∫£o c√≥ c·ªôt last_seen_dt chu·∫©n h√≥a
        if 'last_seen_dt' not in df_d.columns:
            df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
        
        # T√≠nh s·ªë ph√∫t offline
        df_d['off_min'] = (now_dt - df_d['last_seen_dt']).dt.total_seconds() / 60
        off_15m = df_d[df_d['off_min'] > 15]
        
        features = {
            "total": total,
            "offline_ratio": len(off_15m) / total,
            "avg_off": off_15m['off_min'].mean() if not off_15m.empty else 0,
            "new_1h": len(df_d[(df_d['off_min'] > 0) & (df_d['off_min'] <= 60)]),
            "jitter": np.random.uniform(0.05, 0.15) 
        }
        return features

    @staticmethod
    def run_snapshot(sb, features):
        # Thu·∫≠t to√°n t√≠nh Risk Score c·ªßa 4Oranges
        score = (features['offline_ratio'] * 40 + 
                 min(features['avg_off'] / 1440, 1.0) * 30 + 
                 min(features['new_1h'] / (features['total'] * 0.1 + 1), 1.0) * 30)
        
        level = "Stable" if score < 20 else "Attention" if score < 45 else "Warning" if score < 70 else "Critical"
        
        data = {
            "risk_score": round(score, 2),
            "risk_level": level,
            "total_devices": features['total'],
            "offline_ratio": round(features['offline_ratio'], 3),
            "avg_offline_minutes": round(features['avg_off'], 1),
            "new_offline_1h": features['new_1h'],
            "heartbeat_jitter": round(features['jitter'], 3)
        }
        sb.table("ai_snapshots").insert(data).execute()
        return data

# --- T√çCH H·ª¢P V√ÄO TAB AI ---
def render_ai_tab(df_d, sb):
    now_dt_aware = datetime.now(timezone.utc)
    
    # Sidebar: N√∫t ch·ª•p ·∫£nh h·ªá th·ªëng
    if st.sidebar.button("üì∏ Capture AI Snapshot"):
        with st.spinner("AI ƒëang ph√¢n qu√©t to√†n h·ªá th·ªëng..."):
            feats = AI_Engine_v3.calculate_features(df_d, now_dt_aware)
            AI_Engine_v3.run_snapshot(sb, feats)
            st.toast("ƒê√£ l∆∞u Snapshot th√†nh c√¥ng!")
            time.sleep(0.5)
            st.rerun()

    # Hi·ªÉn th·ªã Dashboard AI
    render_ai_strategic_hub_v3(df_d, now_dt_aware, sb)

# --- T√çCH H·ª¢P V√ÄO TAB IMPORT ---
def render_import_tab(sb):
    render_import_portal(sb)

# --- MAIN APP LOGIC ---
def load_all_data():
    try:
        dev = sb.table("devices").select("*").execute()
        cmd = sb.table("commands").select("*").order("created_at", desc=True).limit(20).execute()
        files = sb.table("file_queue").select("*").order("timestamp", desc=True).execute()
        return pd.DataFrame(dev.data), pd.DataFrame(cmd.data), pd.DataFrame(files.data)
    except: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

df_d, df_c, df_f = load_all_data()

# --- METRICS & HEADER ---
st.title("üçäüçäüçä 4ORANGES AI SYSTEM")
if not df_d.empty:
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
    now_dt = datetime.now(timezone.utc)
    df_d['is_online'] = (now_dt - df_d['last_seen_dt']) < timedelta(minutes=2)
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("T·ªïng thi·∫øt b·ªã", len(df_d))
    m2.metric("üü¢ Tr·ª±c tuy·∫øn", len(df_d[df_d['is_online']]))
    m3.metric("T·∫£i CPU TB", f"{df_d['cpu_usage'].mean():.1f}%")
    m4.metric("Dung l∆∞·ª£ng RAM", f"{df_d['ram_usage'].mean():.1f}%")

# --- NAVIGATION ---
t_mon, t_ctrl, t_file, t_sum, t_ai, t_import, t_tokens, t_sys = st.tabs([
    "üìä GI√ÅM S√ÅT", "üéÆ ƒêI·ªÄU KHI·ªÇN", "üì§ TRUY·ªÄN FILE", "üìú T·ªîNG K·∫æT", "üß† AI INSIGHT", "üì• IMPORT DATA", "üîë TOKEN", "‚öôÔ∏è H·ªÜ TH·ªêNG"
])

with t_mon:
    if not df_d.empty: st.dataframe(df_d[['machine_id', 'status', 'cpu_usage', 'ram_usage', 'last_seen']], use_container_width=True, hide_index=True)

with t_import:
    render_import_portal(sb)

with t_ai:
    if not df_d.empty:
        now_dt_aware = datetime.now(timezone.utc)
        # Gi·∫£ s·ª≠ h√†m render_ai_strategic_hub_v3 ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a
        try:
            render_ai_strategic_hub_v3(df_d, now_dt_aware, sb)
        except: st.info("H·ªá th·ªëng AI ƒëang kh·ªüi t·∫°o...")

with t_sys:
    st.subheader("‚öôÔ∏è Qu·∫£n tr·ªã & T·ªëi ∆∞u h√≥a Database")
    col1, col2 = st.columns(2)
    with col1:
        st.write("Gi·∫£i ph√≥ng dung l∆∞·ª£ng th·ªß c√¥ng.")
        if st.button("üßπ D·ªåN D·∫∏P TO√ÄN B·ªò R√ÅC (X√≥a h·∫øt nh·∫≠t k√Ω DONE)", type="primary", use_container_width=True):
            with st.spinner("ƒêang d·ªçn d·∫πp..."):
                sb.table("file_queue").delete().eq("status", "DONE").execute()
                st.success("ƒê√£ x√≥a to√†n b·ªô nh·∫≠t k√Ω ho√†n t·∫•t!")
                time.sleep(1); st.rerun()
    with col2:
        if not df_f.empty:
            pending = len(df_f[df_f['status'] == 'PENDING'])
            st.metric("M·∫£nh ƒëang ch·ªù truy·ªÅn", pending)
