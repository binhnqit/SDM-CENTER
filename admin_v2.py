import streamlit as st
from supabase import create_client, Client
import pandas as pd
from datetime import datetime, timedelta
import plotly.express as px
import base64, zlib, time

# --- CORE CONFIG & SECURITY ---
SUPABASE_URL = "https://glzdktdphoydqhofszvh.supabase.co"
SUPABASE_KEY = "sb_publishable_MCfri2GPc3dn-bIcx_XJ_A_RxgsF1YU"
ADMIN_PASSWORD = "Qb1100589373@" 

sb: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

st.set_page_config(page_title="4Oranges SDM Lux Secure Pro", layout="wide", initial_sidebar_state="expanded")

# --- STYLE APPLE CSS ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f7; }
    .stMetric { background-color: white; padding: 20px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
    div[data-baseweb="tab-list"] { gap: 15px; }
    div[data-baseweb="tab"] { padding: 10px 20px; background-color: #e5e5e7 !important; border-radius: 10px 10px 0 0 !important; margin-right: 2px; }
    div[data-baseweb="tab"][aria-selected="true"] { background-color: #0071e3 !important; color: white !important; }
    </style>
""", unsafe_allow_html=True)

# --- LOGIN LOGIC ---
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

if not st.session_state['authenticated']:
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.write(""); st.write("") 
        st.markdown("<div style='text-align: center;'><h1 style='color: #1d1d1f;'>üçé SDM Secure Pro</h1><p style='color: #86868b;'>Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u qu·∫£n tr·ªã</p></div>", unsafe_allow_html=True)
        pwd = st.text_input("", type="password", placeholder="Password", label_visibility="collapsed")
        if st.button("ƒêƒÉng nh·∫≠p", use_container_width=True, type="primary"):
            if pwd == ADMIN_PASSWORD:
                st.session_state['authenticated'] = True
                st.rerun()
            else:
                st.error("M·∫≠t kh·∫©u kh√¥ng ch√≠nh x√°c.")
    st.stop()

# --- AUTO-CLEAN ENGINE (ƒê√£ s·ª≠a ƒë·ªïi ƒë·ªÉ gi·ªØ l·∫°i nh·∫≠t k√Ω) ---
def auto_clean():
    try:
        # S·∫øp mu·ªën gi·ªØ 30 ng√†y? Ch·ªâ c·∫ßn s·ª≠a s·ªë 30 ·ªü ƒë√¢y
        retention_days = 30 
        past_date = (datetime.now() - timedelta(days=retention_days)).strftime("%Y-%m-%d")
        
        # X√≥a c√°c b·∫£n ghi ƒë√£ DONE v√† c≈© h∆°n 30 ng√†y
        sb.table("file_queue").delete().eq("status", "DONE").lt("timestamp", past_date).execute()
    except: 
        pass

# --- DATA ENGINE ---
def load_all_data():
    try:
        dev = sb.table("devices").select("*").execute()
        cmd = sb.table("commands").select("*").order("created_at", desc=True).limit(20).execute()
        # L·∫•y file_queue ƒë·ªÉ th·ªëng k√™
        files = sb.table("file_queue").select("*").order("timestamp", desc=True).execute()
        return pd.DataFrame(dev.data), pd.DataFrame(cmd.data), pd.DataFrame(files.data)
    except: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

df_d, df_c, df_f = load_all_data()

# --- HEADER ---
c_head1, c_head2 = st.columns([3, 1])
with c_head1:
    st.title("üçé 4Oranges Lux Management Pro")
    st.caption(f"H·ªá th·ªëng v·∫≠n h√†nh th√¥ng minh v4.4 | {datetime.now().strftime('%d/%m/%Y')}")
with c_head2:
    if st.button("ƒêƒÉng xu·∫•t", use_container_width=True):
        st.session_state['authenticated'] = False
        st.rerun()

# --- METRICS ---
if not df_d.empty:
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'])
    now_dt = datetime.now(df_d['last_seen_dt'].dt.tz)
    df_d['is_online'] = (now_dt - df_d['last_seen_dt']) < timedelta(minutes=2)
    online_now = len(df_d[df_d['is_online']])
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("T·ªïng thi·∫øt b·ªã", len(df_d))
    m2.metric("üü¢ Tr·ª±c tuy·∫øn", online_now, delta=f"{online_now/len(df_d)*100:.1f}%")
    m3.metric("T·∫£i CPU TB", f"{df_d['cpu_usage'].mean():.1f}%")
    m4.metric("Dung l∆∞·ª£ng RAM", f"{df_d['ram_usage'].mean():.1f}%")

# --- NAVIGATION TABS ---
t_mon, t_ctrl, t_file, t_sum, t_offline, t_ai, t_sys = st.tabs([
    "üìä GI√ÅM S√ÅT", "üéÆ ƒêI·ªÄU KHI·ªÇN", "üì§ TRUY·ªÄN FILE", "üìú T·ªîNG K·∫æT", "üïµÔ∏è TRUY V·∫æT", "üß† AI INSIGHT", "‚öôÔ∏è H·ªÜ TH·ªêNG"
])

with t_mon:
    st.subheader("Tr·∫°ng th√°i thi·∫øt b·ªã th·ªùi gian th·ª±c")
    if not df_d.empty:
        st.dataframe(df_d[['machine_id', 'status', 'cpu_usage', 'ram_usage', 'last_seen', 'agent_version']], use_container_width=True, hide_index=True)

with t_ctrl:
    st.subheader("Trung t√¢m l·ªánh chi·∫øn l∆∞·ª£c")
    selected_machines = st.multiselect("Nh·∫Øm m·ª•c ti√™u:", df_d['machine_id'].tolist() if not df_d.empty else [])
    c_btn1, c_btn2, _ = st.columns([1, 1, 4])
    if c_btn1.button("üîí KH√ìA M√ÅY", use_container_width=True, type="primary"):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "LOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh LOCK ƒë√£ ph√°t ƒëi!")
    if c_btn2.button("üîì M·ªû M√ÅY", use_container_width=True):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "UNLOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh UNLOCK ƒë√£ ph√°t ƒëi!")

with t_file:
    st.subheader("Ph√°t h√†nh b·ªô d·ªØ li·ªáu SDF")
    file_up = st.file_uploader("K√©o th·∫£ file .SDF", type=['sdf'])
    active_machines = df_d['machine_id'].unique().tolist() if not df_d.empty else []
    f_targets = st.multiselect("ƒê·∫°i l√Ω nh·∫≠n m·ª•c ti√™u:", active_machines)
    
    if st.button("üöÄ K√çCH HO·∫†T ƒê·ªíNG B·ªò") and file_up and f_targets:
        with st.status("ƒêang chu·∫©n b·ªã g√≥i tin..."):
            encoded = base64.b64encode(zlib.compress(file_up.getvalue())).decode('utf-8')
            chunks = [encoded[i:i+100000] for i in range(0, len(encoded), 100000)]
            
            for m in f_targets:
                # S·ª¨A L·ªñI 1: Batch_ID ƒë·ªôc nh·∫•t cho m·ªói m√°y ƒë·ªÉ tr√°nh Agent update ch·ªìng ch√©o
                batch_id = f"{m}_{file_up.name}_{int(time.time())}"
                payload = []
                for i, c in enumerate(chunks):
                    payload.append({
                        "machine_id": m, 
                        "file_name": file_up.name, 
                        "data_chunk": c,
                        "part_info": f"PART_{i+1}/{len(chunks)}", 
                        "timestamp": batch_id, # D√πng batch_id l√†m timestamp ƒë·ªãnh danh
                        "status": "PENDING"
                    })
                # Insert theo l√¥ 50 b·∫£n ghi
                for j in range(0, len(payload), 50):
                    sb.table("file_queue").insert(payload[j:j+50]).execute()
            st.success("ƒê√£ ph√°t h√†nh l·ªánh ƒë·ªìng b·ªô!")
            time.sleep(1); st.rerun()

# --- TAB T·ªîNG K·∫æT (S·ª≠a L·ªói Hi·ªÉn Th·ªã) ---
with t_sum:
    st.subheader("üìú Nh·∫≠t k√Ω v·∫≠n h√†nh h·ªá th·ªëng")
    if not df_f.empty:
        # S·ª¨A L·ªñI 2: ∆Øu ti√™n tr·∫°ng th√°i DONE khi Groupby
        # Chuy·ªÉn status v·ªÅ d·∫°ng category ƒë·ªÉ sort: DONE s·∫Ω ƒë·ª©ng tr∆∞·ªõc PENDING
        df_f['status_rank'] = df_f['status'].apply(lambda x: 1 if x == "DONE" else 0)
        
        log_df = (
            df_f.sort_values(by=['status_rank', 'timestamp'], ascending=[False, False])
            .drop_duplicates(subset=['machine_id', 'timestamp']) # timestamp ·ªü ƒë√¢y ch√≠nh l√† batch_id
        )
        
        log_df['Tr·∫°ng th√°i'] = log_df['status'].apply(lambda x: "‚úÖ Ho√†n t·∫•t" if x == "DONE" else "‚è≥ ƒêang nh·∫≠n...")
        
        st.dataframe(
            log_df[['machine_id', 'file_name', 'timestamp', 'Tr·∫°ng th√°i']],
            column_config={
                "machine_id": "M√°y tr·∫°m",
                "file_name": "T√™n File",
                "timestamp": "M√£ Batch (ID)",
                "Tr·∫°ng th√°i": st.column_config.TextColumn("K·∫øt qu·∫£")
            },
            use_container_width=True, hide_index=True
        )
    else:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ truy·ªÅn file.")

with t_offline:
    st.subheader("üïµÔ∏è Ki·ªÉm so√°t v·∫Øng m·∫∑t")
    threshold = st.slider("Ng∆∞·ª°ng v·∫Øng m·∫∑t (ng√†y):", 1, 90, 30)
    if not df_d.empty:
        long_offline = df_d[df_d['last_seen_dt'] < (now_dt - timedelta(days=threshold))]
        st.dataframe(long_offline, use_container_width=True)

def render_ai_strategic_hub(df_d, now_dt):
    st.markdown("### üß† SDM AI Strategic Hub (V2.0)")
    
    # --- L·ªöP 1: FEATURE ENGINEERING (T√≠nh to√°n ch·ªâ s·ªë th√¥ng minh) ---
    if df_d.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch AI.")
        return

    total_devices = len(df_d)
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
    df_d['offline_minutes'] = (now_dt - df_d['last_seen_dt']).dt.total_seconds() / 60
    
    # T√≠nh c√°c features c·ªët l√µi
    offline_ratio = len(df_d[df_d['offline_minutes'] > 15]) / total_devices
    avg_offline = df_d[df_d['offline_minutes'] > 15]['offline_minutes'].mean() or 0
    new_offline_1h = len(df_d[(df_d['offline_minutes'] > 0) & (df_d['offline_minutes'] <= 60)])
    
    # --- L·ªöP 2: SCORING (Thay If-Else b·∫±ng Risk Score 0.0 -> 1.0) ---
    # Tr·ªçng s·ªë: T·ª∑ l·ªá offline (40%) + Th·ªùi gian offline TB (30%) + T·ªëc ƒë·ªô r·ªõt m·∫°ng m·ªõi (30%)
    risk_score = (
        min(offline_ratio / 0.5, 1.0) * 0.4 + 
        min(avg_offline / 1440, 1.0) * 0.3 + 
        min(new_offline_1h / (total_devices * 0.2 + 1), 1.0) * 0.3
    )
    
    tab_summary, tab_risk, tab_forecast, tab_rag = st.tabs([
        "üî≠ T·ªîNG QUAN CHI·∫æN L∆Ø·ª¢C", "‚ö†Ô∏è PH√ÇN T√çCH R·ª¶I RO", "üîÆ D·ª∞ B√ÅO V·∫¨N H√ÄNH", "üí¨ TR·ª¢ L√ù RAG"
    ])

    with tab_summary:
        # L·ªöP 4: MEMORY & TREND (Gi·∫£ l·∫≠p trend t·ª´ Risk Score)
        c1, c2, c3 = st.columns(3)
        
        # Gi·∫£ l·∫≠p trend (Trong th·ª±c t·∫ø s·∫Ω query t·ª´ b·∫£ng ai_snapshots)
        prev_risk_score = risk_score * 0.9 # Gi·∫£ l·∫≠p h√¥m qua t·ªët h∆°n
        risk_delta = risk_score - prev_risk_score
        
        c1.metric("Ch·ªâ s·ªë r·ªßi ro h·ªá th·ªëng", f"{risk_score:.2f}", 
                  delta=f"{risk_delta:.2f}", delta_color="inverse")
        
        status_label = "·ªîN ƒê·ªäNH" if risk_score < 0.3 else "C·∫¶N CH√ö √ù" if risk_score < 0.6 else "NGUY C∆† CAO"
        c2.metric("Tr·∫°ng th√°i AI x√°c ƒë·ªãnh", status_label)
        c3.metric("Health Score", f"{int((1-risk_score)*100)}%")

        # Bi·ªÉu ƒë·ªì di·ªÖn bi·∫øn r·ªßi ro (Memory Layer)
        st.write("**Di·ªÖn bi·∫øn r·ªßi ro 24h qua (AI Snapshot)**")
        # Gi·∫£ l·∫≠p d·ªØ li·ªáu chu·ªói th·ªùi gian
        chart_data = pd.DataFrame({
            'Time': [now_dt - timedelta(hours=i) for i in range(24, 0, -1)],
            'Risk': np.random.uniform(risk_score-0.1, risk_score+0.1, 24)
        })
        st.line_chart(chart_data, x='Time', y='Risk')

    with tab_risk:
        st.markdown("#### üîç Evidence-based Trace (B·∫±ng ch·ª©ng r·ªßi ro)")
        # Ph√¢n lo·∫°i r·ªßi ro theo c·ª•m (Clustering gi·∫£ l·∫≠p)
        col_r1, col_r2 = st.columns(2)
        
        with col_r1:
            st.write("**Top 5 m√°y g√¢y nhi·ªÖu h·ªá th·ªëng (Anomaly)**")
            anomaly_df = df_d.sort_values('offline_minutes', ascending=False).head(5)
            st.dataframe(anomaly_df[['machine_id', 'offline_minutes', 'status']], use_container_width=True)
            
        with col_r2:
            # L·ªöP 3: AI NARRATIVE (Gi·∫£i th√≠ch b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n)
            st.info("**AI Narrative Analysis**")
            confidence = "High" if total_devices > 10 else "Low"
            st.write(f"""
            - **Hi·ªán t∆∞·ª£ng:** T·ª∑ l·ªá m√°y r·ªõt m·∫°ng ƒë·∫°t {offline_ratio*100:.1f}%.
            - **Nguy√™n nh√¢n:** Ph√°t hi·ªán c·ª•m r·ªõt m·∫°ng t·∫≠p trung trong 1 gi·ªù qua ({new_offline_1h} m√°y). 
            - **Khuy·∫øn ngh·ªã:** Ki·ªÉm tra h·∫° t·∫ßng Cloud Supabase ho·∫∑c ƒë∆∞·ªùng truy·ªÅn khu v·ª±c tr·ªçng ƒëi·ªÉm.
            - **ƒê·ªô tin c·∫≠y:** {confidence} (D·ª±a tr√™n {total_devices} m·∫´u)
            """)

    with tab_forecast:
        st.markdown("#### üîÆ Predictive Maintenance (D·ª± b√°o b·∫£o tr√¨)")
        # D·ª± b√°o d·ª±a tr√™n Linear Regression ƒë∆°n gi·∫£n (Gi·∫£ l·∫≠p)
        st.success("D·ª± b√°o: 72 gi·ªù t·ªõi h·ªá th·ªëng s·∫Ω duy tr√¨ ·ªü m·ª©c r·ªßi ro th·∫•p.")
        
        # D·ª± b√°o v·∫≠t t∆∞ (Tinh m√†u) - D·ª±a tr√™n s·∫£n l∆∞·ª£ng ·∫£o
        st.write("**D·ª± b√°o h·∫øt tinh m√†u (AI Forecast - Baseline comparison)**")
        pred_data = pd.DataFrame({
            'ƒê·∫°i l√Ω': ['ƒê·∫°i l√Ω Long An', 'ƒê·∫°i l√Ω B√¨nh T√¢n', 'ƒê·∫°i l√Ω Th·ªß ƒê·ª©c'],
            'X√°c su·∫•t h·∫øt m√†u (%)': [85, 62, 45],
            'Th·ªùi gian d·ª± ki·∫øn': ['1.5 ng√†y', '3 ng√†y', '4.2 ng√†y']
        })
        st.table(pred_data)

    with tab_rag:
        # L·ªõp t∆∞∆°ng t√°c LLM
        st.markdown("#### üí¨ Tr·ª£ l√Ω Ops Intelligence")
        st.text_input("H·ªèi AI v·ªÅ d·ªØ li·ªáu v·∫≠n h√†nh:", placeholder="T·∫°i sao Risk Score h√¥m nay l·∫°i tƒÉng?")
        st.caption("Tr·ª£ l√Ω s·∫Ω ph√¢n t√≠ch b·∫£ng Features v√† Snapshot ƒë·ªÉ tr·∫£ l·ªùi s·∫øp.")
    with t_ai:
    # G·ªçi h√†m x·ª≠ l√Ω AI ƒë√£ ƒë·ªãnh nghƒ©a ·ªü tr√™n
    # Truy·ªÅn v√†o df_d (d·ªØ li·ªáu m√°y) v√† now_dt (th·ªùi gian hi·ªán t·∫°i)
    if not df_d.empty:
        render_ai_strategic_hub(df_d, now_dt)
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu thi·∫øt b·ªã ƒë·ªÉ ph√¢n t√≠ch AI.")
with t_sys:
    st.subheader("‚öôÔ∏è Qu·∫£n tr·ªã & T·ªëi ∆∞u h√≥a Database")
    col1, col2 = st.columns(2)
    with col1:
        st.write("Gi·∫£i ph√≥ng dung l∆∞·ª£ng th·ªß c√¥ng.")
        if st.button("üßπ D·ªåN D·∫∏P TO√ÄN B·ªò R√ÅC (X√≥a h·∫øt nh·∫≠t k√Ω DONE)", type="primary", use_container_width=True):
            with st.spinner("ƒêang d·ªçn d·∫πp..."):
                sb.table("file_queue").delete().eq("status", "DONE").execute()
                st.success("ƒê√£ x√≥a to√†n b·ªô nh·∫≠t k√Ω ho√†n t·∫•t!")
                time.sleep(1); st.rerun()
    with col2:
        if not df_f.empty:
            pending = len(df_f[df_f['status'] == 'PENDING'])
            st.metric("M·∫£nh ƒëang ch·ªù truy·ªÅn", pending)
