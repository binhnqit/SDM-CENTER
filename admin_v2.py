import streamlit as st
from supabase import create_client, Client
import pandas as pd
from datetime import datetime, timedelta, timezone  # Th√™m timezone v√†o ƒë√¢y
import plotly.express as px
import base64, zlib, time
import streamlit as st

# --- CORE CONFIG FROM SECRETS ---
# Kh√¥ng c√≤n hard-code, b·∫£o m·∫≠t tuy·ªát ƒë·ªëi khi chia s·∫ª code
SUPABASE_URL = st.secrets["supabase"]["url"]
SUPABASE_KEY = st.secrets["supabase"]["key"]
ADMIN_PASSWORD = st.secrets["auth"]["admin_password"]

# C√°c ph·∫ßn kh·ªüi t·∫°o Client gi·ªØ nguy√™n
sb: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

st.set_page_config(page_title="4Oranges SDM Lux Secure Pro", layout="wide", initial_sidebar_state="expanded")

# --- STYLE APPLE CSS ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f7; }
    .stMetric { background-color: white; padding: 20px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
    div[data-baseweb="tab-list"] { gap: 15px; }
    div[data-baseweb="tab"] { padding: 10px 20px; background-color: #e5e5e7 !important; border-radius: 10px 10px 0 0 !important; margin-right: 2px; }
    div[data-baseweb="tab"][aria-selected="true"] { background-color: #0071e3 !important; color: white !important; }
    </style>
""", unsafe_allow_html=True)

# --- LOGIN LOGIC ---
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

if not st.session_state['authenticated']:
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.write(""); st.write("") 
        st.markdown("<div style='text-align: center;'><h1 style='color: #1d1d1f;'>üçäüçäüçäüçä 4Oranges Secure</h1><p style='color: #86868b;'>Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u qu·∫£n tr·ªã</p></div>", unsafe_allow_html=True)
        pwd = st.text_input("", type="password", placeholder="Password", label_visibility="collapsed")
        if st.button("ƒêƒÉng nh·∫≠p", use_container_width=True, type="primary"):
            if pwd == ADMIN_PASSWORD:
                st.session_state['authenticated'] = True
                st.rerun()
            else:
                st.error("M·∫≠t kh·∫©u kh√¥ng ch√≠nh x√°c.")
    st.stop()

# --- AUTO-CLEAN ENGINE (ƒê√£ s·ª≠a ƒë·ªïi ƒë·ªÉ gi·ªØ l·∫°i nh·∫≠t k√Ω) ---
def auto_clean():
    try:
        # S·∫øp mu·ªën gi·ªØ 30 ng√†y? Ch·ªâ c·∫ßn s·ª≠a s·ªë 30 ·ªü ƒë√¢y
        retention_days = 30 
        past_date = (datetime.now() - timedelta(days=retention_days)).strftime("%Y-%m-%d")
        
        # X√≥a c√°c b·∫£n ghi ƒë√£ DONE v√† c≈© h∆°n 30 ng√†y
        sb.table("file_queue").delete().eq("status", "DONE").lt("timestamp", past_date).execute()
    except: 
        pass
def render_import_portal(sb):
    st.markdown("""
        <div style="background-color: #0071e3; padding: 20px; border-radius: 15px; color: white; margin-bottom: 20px;">
            <h2 style="margin:0;">üì• AI Data Port</h2>
            <p style="margin:0; opacity: 0.8;">H·ªá th·ªëng n·∫°p d·ªØ li·ªáu l·ªãch s·ª≠ pha m√†u (DispenseHistory.csv)</p>
        </div>
    """, unsafe_allow_html=True)

    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.info("üí° **H∆∞·ªõng d·∫´n:** Xu·∫•t file .csv t·ª´ ph·∫ßn m·ªÅm pha m√†u v√† t·∫£i l√™n ƒë√¢y ƒë·ªÉ AI ph√¢n t√≠ch s·∫£n l∆∞·ª£ng v√† l·ªói k·ªπ thu·∫≠t.")
        # L·∫•y danh s√°ch m√°y ƒë·ªÉ g√°n d·ªØ li·ªáu
        res_dev = sb.table("devices").select("machine_id").execute()
        list_machines = [d['machine_id'] for d in res_dev.data] if res_dev.data else ["Unknown"]
        selected_target = st.selectbox("üéØ G√°n d·ªØ li·ªáu cho m√°y:", list_machines)
        
        uploaded_file = st.file_uploader("K√©o th·∫£ file .csv v√†o ƒë√¢y", type=['csv'])

    if uploaded_file is not None:
        try:
            # ƒê·ªçc d·ªØ li·ªáu
            df = pd.read_csv(uploaded_file)
            
            # --- PH√ÇN T√çCH NHANH (PREVIEW) ---
            with c2:
                st.write("üîç **Xem tr∆∞·ªõc d·ªØ li·ªáu:**")
                # T√≠nh t·ªïng th·ª±c t·∫ø t·ª´ c√°c Line Dispensed (Spec c·ªßa s·∫øp)
                line_cols = [c for c in df.columns if 'LINES_DISPENSED_AMOUNT' in c]
                df['ACTUAL_TOTAL'] = df[line_cols].sum(axis=1)
                
                # T√≠nh sai s·ªë
                df['ERROR_GAP'] = (df['WANTED_AMOUNT'] - df['ACTUAL_TOTAL']).abs()
                
                # Hi·ªÉn th·ªã s·ªë li·ªáu t·ªïng quan
                m1, m2, m3 = st.columns(3)
                m1.metric("T·ªïng m·∫ª pha", len(df))
                m2.metric("Doanh s·ªë", f"{df['PRICE'].sum():,.0f} VND")
                m3.metric("Sai s·ªë TB", f"{df['ERROR_GAP'].mean():.4f}")

                st.dataframe(df[['DISPENSED_DATE', 'PRODUCT_NAME', 'COLOR_NAME', 'WANTED_AMOUNT', 'ACTUAL_TOTAL', 'PRICE']].head(10), use_container_width=True)

            # --- N√öT K√çCH HO·∫†T ---
            if st.button("üöÄ X√ÅC NH·∫¨N IMPORT V√ÄO AI CLOUD", use_container_width=True, type="primary"):
                with st.status("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu cho AI Engine..."):
                    # Ch·ªâ l·ªçc l·∫•y c√°c c·ªôt quan tr·ªçng ƒë·ªÉ t·ªëi ∆∞u b·ªô nh·ªõ Supabase
                    import_df = pd.DataFrame({
                        'machine_id': selected_target,
                        'dispensed_date': pd.to_datetime(df['DISPENSED_DATE']).dt.strftime('%Y-%m-%dT%H:%M:%S%z'),
                        'color_name': df['COLOR_NAME'],
                        'product_name': df['PRODUCT_NAME'],
                        'wanted_amount': df['WANTED_AMOUNT'],
                        'actual_amount': df['ACTUAL_TOTAL'],
                        'error_gap': df['ERROR_GAP'],
                        'price': df['PRICE'],
                        'duration_ms': df[[c for c in df.columns if 'DURATION_MILLISECONDS' in c]].sum(axis=1)
                    })
                    
                    # Chuy·ªÉn ƒë·ªïi sang dict ƒë·ªÉ insert
                    data_to_insert = import_df.to_dict(orient='records')
                    
                    # Insert theo l√¥ (tr√°nh qu√° t·∫£i API)
                    batch_size = 100
                    for i in range(0, len(data_to_insert), batch_size):
                        sb.table("color_mix_logs").insert(data_to_insert[i:i+batch_size]).execute()
                
                st.success(f"ƒê√£ n·∫°p th√†nh c√¥ng {len(df)} b·∫£n ghi cho m√°y {selected_target}!")
                st.balloons()
                time.sleep(1)
                st.rerun()

        except Exception as e:
            st.error(f"‚ùå L·ªói ƒë·ªãnh d·∫°ng file: {str(e)}")
            st.warning("Vui l√≤ng ki·ªÉm tra l·∫°i file CSV c√≥ ƒë√∫ng ƒë·ªãnh d·∫°ng c·ªßa m√°y pha m√†u kh√¥ng.")

# --- ƒê·ª´ng qu√™n th√™m g·ªçi h√†m n√†y v√†o tab t∆∞∆°ng ·ª©ng ·ªü ph·∫ßn ƒëi·ªÅu h∆∞·ªõng ch√≠nh ---
# with t_import:
#     render_import_portal(sb)
# --- DATA ENGINE ---
def load_all_data():
    try:
        dev = sb.table("devices").select("*").execute()
        cmd = sb.table("commands").select("*").order("created_at", desc=True).limit(20).execute()
        # L·∫•y file_queue ƒë·ªÉ th·ªëng k√™
        files = sb.table("file_queue").select("*").order("timestamp", desc=True).execute()
        return pd.DataFrame(dev.data), pd.DataFrame(cmd.data), pd.DataFrame(files.data)
    except: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

df_d, df_c, df_f = load_all_data()

# --- HEADER ---
c_head1, c_head2 = st.columns([3, 1])
with c_head1:
    st.title("üçäüçäüçäüçä H·ªÜ TH·ªêNG QU·∫¢N L√ù M√ÅY PHA M√ÄU 4ORANGES - AI")
    st.caption(f"H·ªá th·ªëng v·∫≠n h√†nh th√¥ng minh v4.4 | {datetime.now().strftime('%d/%m/%Y')}")
with c_head2:
    if st.button("ƒêƒÉng xu·∫•t", use_container_width=True):
        st.session_state['authenticated'] = False
        st.rerun()

# --- METRICS ---
if not df_d.empty:
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'])
    now_dt = datetime.now(df_d['last_seen_dt'].dt.tz)
    df_d['is_online'] = (now_dt - df_d['last_seen_dt']) < timedelta(minutes=2)
    online_now = len(df_d[df_d['is_online']])
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("T·ªïng thi·∫øt b·ªã", len(df_d))
    m2.metric("üü¢ Tr·ª±c tuy·∫øn", online_now, delta=f"{online_now/len(df_d)*100:.1f}%")
    m3.metric("T·∫£i CPU TB", f"{df_d['cpu_usage'].mean():.1f}%")
    m4.metric("Dung l∆∞·ª£ng RAM", f"{df_d['ram_usage'].mean():.1f}%")

# --- NAVIGATION TABS ---
# --- TRONG PH·∫¶N KHAI B√ÅO TABS ---
t_mon, t_ctrl, t_file, t_sum, t_offline, t_ai, t_tokens, t_sys = st.tabs([
    "üìä GI√ÅM S√ÅT", "üéÆ ƒêI·ªÄU KHI·ªÇN", "üì§ TRUY·ªÄN FILE", "üìú T·ªîNG K·∫æT", "üïµÔ∏è TRUY V·∫æT", "üß† AI INSIGHT", "üîë QU·∫¢N L√ù TOKEN", "‚öôÔ∏è H·ªÜ TH·ªêNG"
])

# --- N·ªòI DUNG TAB QU·∫¢N L√ù TOKEN ---
with t_tokens:
    st.subheader("üîë Ph√™ duy·ªát thi·∫øt b·ªã m·ªõi (Security Gate)")
    
    # L·∫•y d·ªØ li·ªáu t·ª´ b·∫£ng device_tokens
    res_tokens = sb.table("device_tokens").select("*").execute()
    df_tokens = pd.DataFrame(res_tokens.data)

    if not df_tokens.empty:
        # Hi·ªÉn th·ªã danh s√°ch ch·ªù duy·ªát
        st.write("**Danh s√°ch thi·∫øt b·ªã y√™u c·∫ßu gia nh·∫≠p:**")
        for index, row in df_tokens.iterrows():
            col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
            col1.text(f"ID: {row['machine_id']}")
            col2.text(f"Token: {row['token'][:10]}...")
            
            status = "üü¢ ƒê√£ duy·ªát" if row['is_active'] else "üü° Ch·ªù duy·ªát"
            col3.info(status)
            
            if not row['is_active']:
                if col4.button("PH√ä DUY·ªÜT", key=f"app_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": True}).eq("machine_id", row['machine_id']).execute()
                    st.success(f"ƒê√£ c·∫•p quy·ªÅn cho {row['machine_id']}")
                    time.sleep(1); st.rerun()
            else:
                if col4.button("THU H·ªíI", key=f"rev_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": False}).eq("machine_id", row['machine_id']).execute()
                    st.warning(f"ƒê√£ ng·∫Øt quy·ªÅn {row['machine_id']}")
                    time.sleep(1); st.rerun()
    else:
        st.info("Ch∆∞a c√≥ thi·∫øt b·ªã n√†o g·ª≠i y√™u c·∫ßu Token.")

    # Ph·∫ßn g√°n Token th·ªß c√¥ng (N·∫øu s·∫øp mu·ªën c·∫•p tr∆∞·ªõc cho ƒë·∫°i l√Ω)
    with st.expander("‚ûï C·∫•p Token th·ªß c√¥ng"):
        new_id = st.text_input("Nh·∫≠p Machine ID:")
        new_owner = st.text_input("T√™n ƒë·∫°i l√Ω:")
        if st.button("T·∫†O TOKEN"):
            new_token = base64.b64encode(os.urandom(24)).decode('utf-8')
            sb.table("device_tokens").insert({
                "machine_id": new_id, 
                "token": new_token, 
                "assigned_to": new_owner,
                "is_active": True
            }).execute()
            st.success(f"ƒê√£ c·∫•p Token cho {new_owner}")

with t_mon:
    st.subheader("Tr·∫°ng th√°i thi·∫øt b·ªã th·ªùi gian th·ª±c")
    if not df_d.empty:
        st.dataframe(df_d[['machine_id', 'status', 'cpu_usage', 'ram_usage', 'last_seen', 'agent_version']], use_container_width=True, hide_index=True)

with t_ctrl:
    st.subheader("Trung t√¢m l·ªánh chi·∫øn l∆∞·ª£c")
    selected_machines = st.multiselect("Nh·∫Øm m·ª•c ti√™u:", df_d['machine_id'].tolist() if not df_d.empty else [])
    c_btn1, c_btn2, _ = st.columns([1, 1, 4])
    if c_btn1.button("üîí KH√ìA M√ÅY", use_container_width=True, type="primary"):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "LOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh LOCK ƒë√£ ph√°t ƒëi!")
    if c_btn2.button("üîì M·ªû M√ÅY", use_container_width=True):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "UNLOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh UNLOCK ƒë√£ ph√°t ƒëi!")

with t_file:
    st.subheader("Ph√°t h√†nh b·ªô d·ªØ li·ªáu SDF")
    file_up = st.file_uploader("K√©o th·∫£ file .SDF", type=['sdf'])
    active_machines = df_d['machine_id'].unique().tolist() if not df_d.empty else []
    f_targets = st.multiselect("ƒê·∫°i l√Ω nh·∫≠n m·ª•c ti√™u:", active_machines)
    
    if st.button("üöÄ K√çCH HO·∫†T ƒê·ªíNG B·ªò") and file_up and f_targets:
        with st.status("ƒêang chu·∫©n b·ªã g√≥i tin..."):
            encoded = base64.b64encode(zlib.compress(file_up.getvalue())).decode('utf-8')
            chunks = [encoded[i:i+100000] for i in range(0, len(encoded), 100000)]
            
            for m in f_targets:
                # S·ª¨A L·ªñI 1: Batch_ID ƒë·ªôc nh·∫•t cho m·ªói m√°y ƒë·ªÉ tr√°nh Agent update ch·ªìng ch√©o
                batch_id = f"{m}_{file_up.name}_{int(time.time())}"
                payload = []
                for i, c in enumerate(chunks):
                    payload.append({
                        "machine_id": m, 
                        "file_name": file_up.name, 
                        "data_chunk": c,
                        "part_info": f"PART_{i+1}/{len(chunks)}", 
                        "timestamp": batch_id, # D√πng batch_id l√†m timestamp ƒë·ªãnh danh
                        "status": "PENDING"
                    })
                # Insert theo l√¥ 50 b·∫£n ghi
                for j in range(0, len(payload), 50):
                    sb.table("file_queue").insert(payload[j:j+50]).execute()
            st.success("ƒê√£ ph√°t h√†nh l·ªánh ƒë·ªìng b·ªô!")
            time.sleep(1); st.rerun()

# --- TAB T·ªîNG K·∫æT (S·ª≠a L·ªói Hi·ªÉn Th·ªã) ---
with t_sum:
    st.subheader("üìú Nh·∫≠t k√Ω v·∫≠n h√†nh h·ªá th·ªëng")
    if not df_f.empty:
        # S·ª¨A L·ªñI 2: ∆Øu ti√™n tr·∫°ng th√°i DONE khi Groupby
        # Chuy·ªÉn status v·ªÅ d·∫°ng category ƒë·ªÉ sort: DONE s·∫Ω ƒë·ª©ng tr∆∞·ªõc PENDING
        df_f['status_rank'] = df_f['status'].apply(lambda x: 1 if x == "DONE" else 0)
        
        log_df = (
            df_f.sort_values(by=['status_rank', 'timestamp'], ascending=[False, False])
            .drop_duplicates(subset=['machine_id', 'timestamp']) # timestamp ·ªü ƒë√¢y ch√≠nh l√† batch_id
        )
        
        log_df['Tr·∫°ng th√°i'] = log_df['status'].apply(lambda x: "‚úÖ Ho√†n t·∫•t" if x == "DONE" else "‚è≥ ƒêang nh·∫≠n...")
        
        st.dataframe(
            log_df[['machine_id', 'file_name', 'timestamp', 'Tr·∫°ng th√°i']],
            column_config={
                "machine_id": "M√°y tr·∫°m",
                "file_name": "T√™n File",
                "timestamp": "M√£ Batch (ID)",
                "Tr·∫°ng th√°i": st.column_config.TextColumn("K·∫øt qu·∫£")
            },
            use_container_width=True, hide_index=True
        )
    else:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ truy·ªÅn file.")

with t_offline:
    st.subheader("üïµÔ∏è Ki·ªÉm so√°t v·∫Øng m·∫∑t")
    threshold = st.slider("Ng∆∞·ª°ng v·∫Øng m·∫∑t (ng√†y):", 1, 90, 30)
    if not df_d.empty:
        long_offline = df_d[df_d['last_seen_dt'] < (now_dt - timedelta(days=threshold))]
        st.dataframe(long_offline, use_container_width=True)

import numpy as np # ƒê·∫£m b·∫£o s·∫øp ƒë√£ import th∆∞ vi·ªán n√†y ·ªü ƒë·∫ßu file

# --- TR∆Ø·ªöC H·∫æT: PH·∫¢I C√ì CLASS N√ÄY TH√å TAB AI M·ªöI CH·∫†Y ƒê∆Ø·ª¢C ---
class AI_Engine_v3:
    @staticmethod
    def calculate_features(df_d, now_dt):
        total = len(df_d)
        if total == 0: return None
        if 'last_seen_dt' not in df_d.columns:
            df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
        
        df_d['off_min'] = (now_dt - df_d['last_seen_dt']).dt.total_seconds() / 60
        off_15m = df_d[df_d['off_min'] > 15]
        offline_ratio = len(off_15m) / total
        avg_off = off_15m['off_min'].mean() if not off_15m.empty else 0
        new_off_1h = len(df_d[(df_d['off_min'] > 0) & (df_d['off_min'] <= 60)])
        jitter = np.random.uniform(0.05, 0.15) 
        return {"total": total, "offline_ratio": offline_ratio, "avg_off": avg_off, "new_1h": new_off_1h, "jitter": jitter}

    @staticmethod
    def run_snapshot(sb, features):
        score = (features['offline_ratio'] * 40 + min(features['avg_off'] / 1440, 1.0) * 30 + min(features['new_1h'] / (features['total'] * 0.1 + 1), 1.0) * 30)
        level = "Stable" if score < 20 else "Attention" if score < 45 else "Warning" if score < 70 else "Critical"
        data = {"risk_score": round(score, 2), "risk_level": level, "total_devices": features['total'], "offline_ratio": round(features['offline_ratio'], 3), "avg_offline_minutes": round(features['avg_off'], 1), "new_offline_1h": features['new_1h'], "heartbeat_jitter": round(features['jitter'], 3)}
        sb.table("ai_snapshots").insert(data).execute()
        return data
def render_import_portal(sb):
    st.subheader("üì• AI Color Mix Data Portal")
    uploaded_file = st.file_uploader("Ch·ªçn file DispenseHistory.csv", type=['csv'])

    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        
        # --- TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (DATA CLEANING) ---
        # AI s·∫Ω t·ªïng h·ª£p Actual Amount t·ª´ c√°c Line th√†nh ph·∫ßn
        lines_amount = [col for col in df.columns if 'LINES_DISPENSED_AMOUNT' in col]
        df['actual_total'] = df[lines_amount].sum(axis=1)
        
        # T√≠nh to√°n sai s·ªë (Error Gap)
        df['error_gap'] = abs(df['WANTED_AMOUNT'] - df['actual_total'])
        
        st.write(f"‚úÖ ƒê√£ nh·∫≠n di·ªán: {len(df)} b·∫£n ghi pha m√†u.")
        
        if st.button("üöÄ X√ÅC NH·∫¨N IMPORT V√ÄO AI ENGINE"):
            # Chuy·ªÉn ƒë·ªïi ƒë·ªÉ ƒë·∫©y l√™n Supabase
            # Ch·ªâ l·∫•y c√°c c·ªôt chi·∫øn l∆∞·ª£c ƒë·ªÉ tr√°nh l√†m n·∫∑ng DB
            clean_df = df[[
                'DISPENSED_DATE', 'COLOR_NAME', 'PRODUCT_NAME', 
                'WANTED_AMOUNT', 'actual_total', 'error_gap', 'PRICE'
            ]].copy()
            
            # G·∫Øn machine_id (V√≠ d·ª• s·∫øp ch·ªçn t·ª´ danh s√°ch ho·∫∑c l·∫•y t·ª´ file)
            data_to_db = clean_df.to_dict(orient='records')
            
            with st.spinner("AI ƒëang h·ªçc d·ªØ li·ªáu..."):
                sb.table("color_mix_logs").insert(data_to_db).execute()
                st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·∫°p v√†o Memory Layer c·ªßa AI!")
# --- H√ÄM RENDER (GI·ªÆ NGUY√äN GIAO DI·ªÜN APPLE) ---
def render_ai_strategic_hub_v3(df_d, now_dt, sb):
    features = AI_Engine_v3.calculate_features(df_d, now_dt)
    res_snap = sb.table("ai_snapshots").select("*").order("created_at", desc=True).limit(24).execute()
    df_snap = pd.DataFrame(res_snap.data)
    
    if df_snap.empty:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu Snapshot. Vui l√≤ng b·∫•m 'Capture AI Snapshot' ·ªü Sidebar.")
        if st.button("K√≠ch ho·∫°t Snapshot ƒë·∫ßu ti√™n"):
            AI_Engine_v3.run_snapshot(sb, features)
            st.rerun()
        return

    latest = df_snap.iloc[0]
    prev = df_snap.iloc[1] if len(df_snap) > 1 else latest
    risk_score = latest['risk_score'] / 100

    st.markdown(f"""
        <div style="background-color: white; padding: 20px; border-radius: 15px; border-left: 10px solid {'#ff3b30' if risk_score > 0.6 else '#ffcc00' if risk_score > 0.3 else '#34c759'};">
            <h2 style="margin:0;">üß† AI Strategic Hub <span style="font-size:14px; color:#86868b;">V3.0 HYBRID</span></h2>
            <p style="color:#86868b; margin:0;">Ph√¢n t√≠ch t·ª´ 5,000 thi·∫øt b·ªã d·ª±a tr√™n AI Memory Layer.</p>
        </div>
    """, unsafe_allow_html=True)
    
    t_overview, t_analysis, t_prediction, t_rag = st.tabs(["üöÄ CHI·∫æN L∆Ø·ª¢C", "üïµÔ∏è TRUY V·∫æT R·ª¶I RO", "üîÆ D·ª∞ B√ÅO", "üí¨ TR·ª¢ L√ù RAG"])

    with t_overview:
        c1, c2, c3 = st.columns(3)
        c1.metric("Risk Index", f"{risk_score:.2f}", delta=round(risk_score - (prev['risk_score']/100), 2), delta_color="inverse")
        c2.metric("System Health", f"{int((1 - risk_score) * 100)}%", delta=f"{latest['total_devices']} M√°y")
        c3.metric("AI Status", latest['risk_level'])
        st.write("---")
        st.markdown("**üìà Di·ªÖn bi·∫øn r·ªßi ro 24h (D·ªØ li·ªáu th·∫≠t t·ª´ DB)**")
        st.line_chart(df_snap, x='created_at', y='risk_score', color="#0071e3")

    with t_analysis:
        st.markdown("#### üïµÔ∏è Ph√¢n t√≠ch b·∫±ng ch·ª©ng (Evidence-based)")
        col_a, col_b = st.columns([1, 1])
        with col_a:
            st.write("**Top 5 m√°y r·ªõt m·∫°ng l√¢u nh·∫•t:**")
            anomaly_df = df_d.sort_values('off_min', ascending=False).head(5)
            st.dataframe(anomaly_df[['machine_id', 'off_min', 'status']], use_container_width=True, hide_index=True)
        with col_b:
            st.info("**AI Narrative (Gi·∫£i thu·∫≠t t·ª± s·ª± V3)**")
            st.write(f"- **Hi·ªán tr·∫°ng:** `{latest['offline_ratio']*100:.1f}%` h·ªá th·ªëng ƒëang offline.\n- **Bi·∫øn ƒë·ªông:** Ph√°t hi·ªán `{latest['new_offline_1h']}` m√°y m·ªõi r·ªõt m·∫°ng.\n- **ƒê·ªô ·ªïn ƒë·ªãnh:** Jitter `{latest['heartbeat_jitter']}`.")
            st.button("T·∫°o b√°o c√°o chi·∫øn l∆∞·ª£c (PDF)", use_container_width=True)

    with t_prediction:
        st.markdown("#### üîÆ D·ª± b√°o b·∫£o tr√¨ & V·∫≠t t∆∞")
        p1, p2 = st.columns(2)
        with p1:
            st.warning("‚ö†Ô∏è **D·ª± b√°o c·∫°n ki·ªát tinh m√†u**")
            st.table(pd.DataFrame({"ƒê·∫°i l√Ω": ["S∆°n H√† N·ªôi", "H√πng T√∫-C·∫ßn Th∆°"], "AI D·ª± b√°o": ["24h t·ªõi", "48h t·ªõi"]}))
        with p2:
            st.success("‚úÖ **D·ª± b√°o t·∫£i tr·ªçng h·ªá th·ªëng**")
            st.info("AI d·ª± b√°o l∆∞u l∆∞·ª£ng file SDF s·∫Ω ƒë·∫°t ƒë·ªânh v√†o chi·ªÅu nay.")

    with t_rag:
        st.markdown("#### üí¨ Tr·ª£ l√Ω AI ƒë·∫∑c quy·ªÅn")
        query = st.text_input("H·ªèi AI v·ªÅ h·ªá th·ªëng:", placeholder="V√≠ d·ª•: T·∫°i sao h√¥m nay Risk Score tƒÉng cao?")
        if query:
            with st.spinner("AI ƒëang truy v·∫•n Memory..."):
                st.chat_message("assistant").write(f"D·ª±a tr√™n Snapshot l√∫c {latest['created_at']}, r·ªßi ro hi·ªán t·∫°i l√† {latest['risk_level']}.")

# --- PH·∫¶N G·ªåI TAB TRONG APP CH√çNH (S·ª¨A L·ªñI TH·ª§T L·ªÄ T·∫†I ƒê√ÇY) ---
with t_ai:
    if not df_d.empty:
        try:
            now_dt_aware = datetime.now(timezone.utc)
            if 'last_seen_dt' not in df_d.columns:
                df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
            
            # Sidebar button ƒë·ªÉ ch·ª•p ·∫£nh h·ªá th·ªëng
            if st.sidebar.button("üì∏ Capture AI Snapshot"):
                feats = AI_Engine_v3.calculate_features(df_d, now_dt_aware)
                AI_Engine_v3.run_snapshot(sb, feats)
                st.toast("ƒê√£ l∆∞u Snapshot th√†nh c√¥ng!")
                time.sleep(0.5)
                st.rerun()

            render_ai_strategic_hub_v3(df_d, now_dt_aware, sb)
        except Exception as e:
            st.error(f"L·ªói AI Engine: {e}")
    else:
        st.info("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ trung t√¢m...")

with t_sys:
    st.subheader("‚öôÔ∏è Qu·∫£n tr·ªã & T·ªëi ∆∞u h√≥a Database")
    col1, col2 = st.columns(2)
    with col1:
        st.write("Gi·∫£i ph√≥ng dung l∆∞·ª£ng th·ªß c√¥ng.")
        if st.button("üßπ D·ªåN D·∫∏P TO√ÄN B·ªò R√ÅC (X√≥a h·∫øt nh·∫≠t k√Ω DONE)", type="primary", use_container_width=True):
            with st.spinner("ƒêang d·ªçn d·∫πp..."):
                sb.table("file_queue").delete().eq("status", "DONE").execute()
                st.success("ƒê√£ x√≥a to√†n b·ªô nh·∫≠t k√Ω ho√†n t·∫•t!")
                time.sleep(1); st.rerun()
    with col2:
        if not df_f.empty:
            pending = len(df_f[df_f['status'] == 'PENDING'])
            st.metric("M·∫£nh ƒëang ch·ªù truy·ªÅn", pending)
