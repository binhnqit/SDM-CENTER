import streamlit as st
from supabase import create_client, Client
import pandas as pd
from datetime import datetime, timedelta, timezone  # Th√™m timezone v√†o ƒë√¢y
import plotly.express as px
import base64, zlib, time
import math
import numpy as np
def sanitize_df(df: pd.DataFrame):
    return (
        df.replace([float("inf"), float("-inf")], None)
          .where(df.notnull(), None)
    )
# --- CORE CONFIG FROM SECRETS ---
# Kh√¥ng c√≤n hard-code, b·∫£o m·∫≠t tuy·ªát ƒë·ªëi khi chia s·∫ª code
SUPABASE_URL = st.secrets["supabase"]["url"]
SUPABASE_KEY = st.secrets["supabase"]["key"]
ADMIN_PASSWORD = st.secrets["auth"]["admin_password"]

# C√°c ph·∫ßn kh·ªüi t·∫°o Client gi·ªØ nguy√™n
sb: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

st.set_page_config(page_title="4Oranges SDM Lux Secure Pro", layout="wide", initial_sidebar_state="expanded")
# --- AUTH PERSIST VIA QUERY PARAM (SAFE REFRESH) ---
if "auth" in st.query_params and st.query_params["auth"] == "1":
    st.session_state['authenticated'] = True
# --- STYLE APPLE CSS ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f7; }
    .stMetric { background-color: white; padding: 20px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
    div[data-baseweb="tab-list"] { gap: 15px; }
    div[data-baseweb="tab"] { padding: 10px 20px; background-color: #e5e5e7 !important; border-radius: 10px 10px 0 0 !important; margin-right: 2px; }
    div[data-baseweb="tab"][aria-selected="true"] { background-color: #0071e3 !important; color: white !important; }
    </style>
""", unsafe_allow_html=True)

# --- LOGIN LOGIC ---
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

if not st.session_state['authenticated']:
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.write(""); st.write("") 
        st.markdown("<div style='text-align: center;'><h1 style='color: #1d1d1f;'>üçäüçäüçäüçä 4Oranges Secure</h1><p style='color: #86868b;'>Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u qu·∫£n tr·ªã</p></div>", unsafe_allow_html=True)
        pwd = st.text_input("", type="password", placeholder="Password", label_visibility="collapsed")
        if st.button("ƒêƒÉng nh·∫≠p", use_container_width=True, type="primary"):
            if pwd == ADMIN_PASSWORD:
                st.session_state['authenticated'] = True
                st.query_params["auth"] = "1" 
                st.rerun()
            else:
                st.error("M·∫≠t kh·∫©u kh√¥ng ch√≠nh x√°c.")
    st.stop()

# --- AUTO-CLEAN ENGINE (ƒê√£ s·ª≠a ƒë·ªïi ƒë·ªÉ gi·ªØ l·∫°i nh·∫≠t k√Ω) ---
def auto_clean():
    try:
        # S·∫øp mu·ªën gi·ªØ 30 ng√†y? Ch·ªâ c·∫ßn s·ª≠a s·ªë 30 ·ªü ƒë√¢y
        retention_days = 30 
        past_date = (datetime.now() - timedelta(days=retention_days)).strftime("%Y-%m-%d")
        
        # X√≥a c√°c b·∫£n ghi ƒë√£ DONE v√† c≈© h∆°n 30 ng√†y
        sb.table("file_queue").delete().eq("status", "DONE").lt("timestamp", past_date).execute()
    except: 
        pass

# --- DATA ENGINE ---
def load_all_data():
    try:
        dev = sb.table("devices").select("*").execute()
        cmd = sb.table("commands").select("*").order("created_at", desc=True).limit(20).execute()
        # L·∫•y file_queue ƒë·ªÉ th·ªëng k√™
        files = sb.table("file_queue").select("*").order("timestamp", desc=True).execute()
        return pd.DataFrame(dev.data), pd.DataFrame(cmd.data), pd.DataFrame(files.data)
    except: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

df_d, df_c, df_f = load_all_data()

# --- HEADER ---
c_head1, c_head2 = st.columns([3, 1])
with c_head1:
    st.title("üçäüçäüçäüçä H·ªÜ TH·ªêNG QU·∫¢N L√ù M√ÅY PHA M√ÄU 4ORANGES - AI")
    st.caption(f"H·ªá th·ªëng v·∫≠n h√†nh th√¥ng minh v4.4 | {datetime.now().strftime('%d/%m/%Y')}")
with c_head2:
    if st.button("ƒêƒÉng xu·∫•t", use_container_width=True):
        st.session_state['authenticated'] = False
        st.rerun()

# --- METRICS ---
if not df_d.empty:
    df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'])
    now_dt = datetime.now(df_d['last_seen_dt'].dt.tz)
    df_d['is_online'] = (now_dt - df_d['last_seen_dt']) < timedelta(minutes=2)
    online_now = len(df_d[df_d['is_online']])
    
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("T·ªïng thi·∫øt b·ªã", len(df_d))
    m2.metric("üü¢ Tr·ª±c tuy·∫øn", online_now, delta=f"{online_now/len(df_d)*100:.1f}%")
    m3.metric("T·∫£i CPU TB", f"{df_d['cpu_usage'].mean():.1f}%")
    m4.metric("Dung l∆∞·ª£ng RAM", f"{df_d['ram_usage'].mean():.1f}%")
# --- NAVIGATION TABS ---
# --- TRONG PH·∫¶N KHAI B√ÅO TABS ---
t_mon, t_ctrl, t_file, t_csv, t_sum, t_offline, t_ai, t_tokens, t_sys = st.tabs([
    "üìä GI√ÅM S√ÅT",
    "üéÆ ƒêI·ªÄU KHI·ªÇN",
    "üì§ TRUY·ªÄN FILE",
    "üì• CSV LEARNING",   # üëà TAB M·ªöI
    "üìú T·ªîNG K·∫æT",
    "üïµÔ∏è TRUY V·∫æT",
    "üß† AI INSIGHT",
    "üîë QU·∫¢N L√ù TOKEN",
    "‚öôÔ∏è H·ªÜ TH·ªêNG"
])
# --- CSV LEARNING TAB ---
def sanitize_for_json(obj):
    """
    Convert Pandas / NumPy values into JSON-safe Python values
    """
    if obj is None:
        return None

    # NaN, NaT
    if isinstance(obj, float) and math.isnan(obj):
        return None
    if pd.isna(obj):
        return None

    # numpy scalar
    if isinstance(obj, (np.integer, np.int64)):
        return int(obj)
    if isinstance(obj, (np.floating, np.float64)):
        if math.isnan(obj) or math.isinf(obj):
            return None
        return float(obj)

    # timestamp
    if isinstance(obj, pd.Timestamp):
        if pd.isna(obj):
            return None
        return obj.isoformat()

    # dict
    if isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}

    # list
    if isinstance(obj, list):
        return [sanitize_for_json(v) for v in obj]

    return obj
with t_csv:
    st.subheader("üì• CSV Learning Memory")
    st.caption("N·∫°p l·ªãch s·ª≠ v·∫≠n h√†nh ƒë·ªÉ AI h·ªçc h√†nh vi th·ª±c t·∫ø")

    csv_file = st.file_uploader(
        "Upload file CSV (Dispense / Mixing / History)",
        type=["csv"]
    )

    if csv_file:
        try:
            df_csv = sanitize_df(pd.read_csv(csv_file))

            st.success(f"ƒê√£ t·∫£i {len(df_csv)} d√≤ng d·ªØ li·ªáu")
            st.dataframe(df_csv.head(100), use_container_width=True)

            if st.button("üß† GHI V√ÄO AI MEMORY", type="primary"):
                records = []

                for _, row in df_csv.iterrows():
                    raw_payload = sanitize_for_json(row.to_dict())
                   
                    records.append({
                        "machine_id": raw_payload.get("machine_id"),
                        "event_time": raw_payload.get("dispense_time") or raw_payload.get("timestamp"),
                        "payload": raw_payload
                    })

                # insert batch an to√†n
                for i in range(0, len(records), 100):
                    sb.table("ai_learning_data").insert(
                        records[i:i+100]
                    ).execute()

                st.toast("AI ƒë√£ ti·∫øp nh·∫≠n d·ªØ li·ªáu h·ªçc h·ªèi!")
                time.sleep(0.5)
                st.rerun()

        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc CSV: {e}")
# --- N·ªòI DUNG TAB QU·∫¢N L√ù TOKEN ---
with t_tokens:
    st.subheader("üîë Ph√™ duy·ªát thi·∫øt b·ªã m·ªõi (Security Gate)")
    
    # L·∫•y d·ªØ li·ªáu t·ª´ b·∫£ng device_tokens
    res_tokens = sb.table("device_tokens").select("*").execute()
    df_tokens = pd.DataFrame(res_tokens.data)

    if not df_tokens.empty:
        # Hi·ªÉn th·ªã danh s√°ch ch·ªù duy·ªát
        st.write("**Danh s√°ch thi·∫øt b·ªã y√™u c·∫ßu gia nh·∫≠p:**")
        for index, row in df_tokens.iterrows():
            col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
            col1.text(f"ID: {row['machine_id']}")
            col2.text(f"Token: {row['token'][:10]}...")
            
            status = "üü¢ ƒê√£ duy·ªát" if row['is_active'] else "üü° Ch·ªù duy·ªát"
            col3.info(status)
            
            if not row['is_active']:
                if col4.button("PH√ä DUY·ªÜT", key=f"app_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": True}).eq("machine_id", row['machine_id']).execute()
                    st.success(f"ƒê√£ c·∫•p quy·ªÅn cho {row['machine_id']}")
                    time.sleep(1); st.rerun()
            else:
                if col4.button("THU H·ªíI", key=f"rev_{row['machine_id']}"):
                    sb.table("device_tokens").update({"is_active": False}).eq("machine_id", row['machine_id']).execute()
                    st.warning(f"ƒê√£ ng·∫Øt quy·ªÅn {row['machine_id']}")
                    time.sleep(1); st.rerun()
    else:
        st.info("Ch∆∞a c√≥ thi·∫øt b·ªã n√†o g·ª≠i y√™u c·∫ßu Token.")

    # Ph·∫ßn g√°n Token th·ªß c√¥ng (N·∫øu s·∫øp mu·ªën c·∫•p tr∆∞·ªõc cho ƒë·∫°i l√Ω)
    with st.expander("‚ûï C·∫•p Token th·ªß c√¥ng"):
        new_id = st.text_input("Nh·∫≠p Machine ID:")
        new_owner = st.text_input("T√™n ƒë·∫°i l√Ω:")
        if st.button("T·∫†O TOKEN"):
            new_token = base64.b64encode(os.urandom(24)).decode('utf-8')
            sb.table("device_tokens").insert({
                "machine_id": new_id, 
                "token": new_token, 
                "assigned_to": new_owner,
                "is_active": True
            }).execute()
            st.success(f"ƒê√£ c·∫•p Token cho {new_owner}")

with t_mon:
    st.subheader("Tr·∫°ng th√°i thi·∫øt b·ªã th·ªùi gian th·ª±c")
    if not df_d.empty:
        st.dataframe(df_d[['machine_id', 'status', 'cpu_usage', 'ram_usage', 'last_seen', 'agent_version']], use_container_width=True, hide_index=True)

with t_ctrl:
    st.subheader("Trung t√¢m l·ªánh chi·∫øn l∆∞·ª£c")
    selected_machines = st.multiselect("Nh·∫Øm m·ª•c ti√™u:", df_d['machine_id'].tolist() if not df_d.empty else [])
    c_btn1, c_btn2, _ = st.columns([1, 1, 4])
    if c_btn1.button("üîí KH√ìA M√ÅY", use_container_width=True, type="primary"):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "LOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh LOCK ƒë√£ ph√°t ƒëi!")
    if c_btn2.button("üîì M·ªû M√ÅY", use_container_width=True):
        if selected_machines:
            sb.table("commands").insert([{"machine_id": m, "command": "UNLOCK"} for m in selected_machines]).execute()
            st.toast("L·ªánh UNLOCK ƒë√£ ph√°t ƒëi!")

with t_file:
    st.subheader("Ph√°t h√†nh b·ªô d·ªØ li·ªáu SDF")
    file_up = st.file_uploader("K√©o th·∫£ file .SDF", type=['sdf'])
    active_machines = df_d['machine_id'].unique().tolist() if not df_d.empty else []
    f_targets = st.multiselect("ƒê·∫°i l√Ω nh·∫≠n m·ª•c ti√™u:", active_machines)
    
    if st.button("üöÄ K√çCH HO·∫†T ƒê·ªíNG B·ªò") and file_up and f_targets:
        with st.status("ƒêang chu·∫©n b·ªã g√≥i tin..."):
            encoded = base64.b64encode(zlib.compress(file_up.getvalue())).decode('utf-8')
            chunks = [encoded[i:i+100000] for i in range(0, len(encoded), 100000)]
            
            for m in f_targets:
                # S·ª¨A L·ªñI 1: Batch_ID ƒë·ªôc nh·∫•t cho m·ªói m√°y ƒë·ªÉ tr√°nh Agent update ch·ªìng ch√©o
                batch_id = f"{m}_{file_up.name}_{int(time.time())}"
                payload = []
                for i, c in enumerate(chunks):
                    payload.append({
                        "machine_id": m, 
                        "file_name": file_up.name, 
                        "data_chunk": c,
                        "part_info": f"PART_{i+1}/{len(chunks)}", 
                        "timestamp": batch_id, # D√πng batch_id l√†m timestamp ƒë·ªãnh danh
                        "status": "PENDING"
                    })
                # Insert theo l√¥ 50 b·∫£n ghi
                for j in range(0, len(payload), 50):
                    sb.table("file_queue").insert(payload[j:j+50]).execute()
            st.success("ƒê√£ ph√°t h√†nh l·ªánh ƒë·ªìng b·ªô!")
            time.sleep(1); st.rerun()

# --- TAB T·ªîNG K·∫æT (S·ª≠a L·ªói Hi·ªÉn Th·ªã) ---
with t_sum:
    st.subheader("üìú Nh·∫≠t k√Ω v·∫≠n h√†nh h·ªá th·ªëng")
    if not df_f.empty:
        # S·ª¨A L·ªñI 2: ∆Øu ti√™n tr·∫°ng th√°i DONE khi Groupby
        # Chuy·ªÉn status v·ªÅ d·∫°ng category ƒë·ªÉ sort: DONE s·∫Ω ƒë·ª©ng tr∆∞·ªõc PENDING
        df_f['status_rank'] = df_f['status'].apply(lambda x: 1 if x == "DONE" else 0)
        
        log_df = (
            df_f.sort_values(by=['status_rank', 'timestamp'], ascending=[False, False])
            .drop_duplicates(subset=['machine_id', 'timestamp']) # timestamp ·ªü ƒë√¢y ch√≠nh l√† batch_id
        )
        
        log_df['Tr·∫°ng th√°i'] = log_df['status'].apply(lambda x: "‚úÖ Ho√†n t·∫•t" if x == "DONE" else "‚è≥ ƒêang nh·∫≠n...")
        
        st.dataframe(
            log_df[['machine_id', 'file_name', 'timestamp', 'Tr·∫°ng th√°i']],
            column_config={
                "machine_id": "M√°y tr·∫°m",
                "file_name": "T√™n File",
                "timestamp": "M√£ Batch (ID)",
                "Tr·∫°ng th√°i": st.column_config.TextColumn("K·∫øt qu·∫£")
            },
            use_container_width=True, hide_index=True
        )
    else:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ truy·ªÅn file.")

with t_offline:
    st.subheader("üïµÔ∏è AI Forensics ‚Äì Truy v·∫øt Offline")
    st.caption("Ph√¢n t√≠ch l·ªãch s·ª≠ gi√°n ƒëo·∫°n ƒë·ªÉ x√°c ƒë·ªãnh c√°c ƒë·∫°i l√Ω c√≥ h·∫° t·∫ßng m·∫°ng kh√¥ng ·ªïn ƒë·ªãnh.")

    # 1. Thanh ƒëi·ªÅu khi·ªÉn ph·∫°m vi
    days = st.slider("Ph·∫°m vi truy v·∫øt (ng√†y)", 1, 60, 14)

    # 2. Truy v·∫•n d·ªØ li·ªáu t·ª´ b·∫£ng device_events
    try:
        res = (
            sb.table("device_events")
              .select("*")
              .eq("event_type", "OFFLINE")
              .gte("detected_at", (datetime.now(timezone.utc) - timedelta(days=days)).isoformat())
              .order("detected_at", desc=True)
              .execute()
        )
        df_evt = pd.DataFrame(res.data)

        if df_evt.empty:
            st.info("‚úÖ H·ªá th·ªëng ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh. Kh√¥ng ph√°t hi·ªán s·ª± ki·ªán offline n√†o trong ph·∫°m vi ƒë√£ ch·ªçn.")
        else:
            # 3. Ph√¢n t√≠ch d·ªØ li·ªáu b·∫±ng bi·ªÉu ƒë·ªì
            st.markdown("### üìà Bi·ªÉu ƒë·ªì t·∫ßn su·∫•t r·ªõt m·∫°ng")
            # ƒê·∫øm s·ªë l·∫ßn offline theo t·ª´ng m√°y ƒë·ªÉ xem "ai l√† tr√πm r·ªõt m·∫°ng"
            off_counts = df_evt['machine_id'].value_counts().reset_index()
            off_counts.columns = ['machine_id', 'count']
            
            fig_off = px.bar(off_counts, x='machine_id', y='count', 
                             title="S·ªë l·∫ßn r·ªõt m·∫°ng theo t·ª´ng thi·∫øt b·ªã",
                             labels={'machine_id': 'M√£ m√°y', 'count': 'S·ªë l·∫ßn'},
                             color='count', color_continuous_scale='Reds')
            st.plotly_chart(fig_off, use_container_width=True)

            # 4. Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
            st.markdown("### üìç Timeline r·ªõt m·∫°ng chi ti·∫øt")
            st.dataframe(
                df_evt[['machine_id', 'detected_at', 'off_minutes', 'cpu_usage', 'ram_usage']],
                column_config={
                    "machine_id": "M√£ m√°y",
                    "detected_at": "Th·ªùi ƒëi·ªÉm ph√°t hi·ªán",
                    "off_minutes": "Th·ªùi gian s·∫≠p (ph√∫t)",
                    "cpu_usage": "CPU l√∫c ƒë√≥",
                    "ram_usage": "RAM l√∫c ƒë√≥"
                },
                use_container_width=True,
                hide_index=True
            )

            # 5. Nh·∫≠n ƒë·ªãnh AI th√¥ng minh h∆°n
            st.markdown("### üß† Nh·∫≠n ƒë·ªãnh AI Forensics")
            
            # T√≠nh to√°n m·ªôt v√†i ch·ªâ s·ªë ƒë·ªÉ "AI" n√≥i chuy·ªán chuy√™n nghi·ªáp h∆°n
            total_off = len(df_evt)
            unique_machines = df_evt['machine_id'].nunique()
            max_off_machine = off_counts.iloc[0]['machine_id'] if not off_counts.empty else "N/A"
            avg_off_time = df_evt['off_minutes'].mean() if 'off_minutes' in df_evt.columns else 0

            st.warning(
                f"**B√°o c√°o h·ªá th·ªëng:** Trong {days} ng√†y qua, ghi nh·∫≠n **{total_off}** s·ª± c·ªë m·∫•t k·∫øt n·ªëi t·ª´ **{unique_machines}** thi·∫øt b·ªã kh√°c nhau. \n\n"
                f"- üö® M√°y tr·∫°m **{max_off_machine}** c√≥ t·∫ßn su·∫•t r·ªõt m·∫°ng cao nh·∫•t.\n"
                f"- ‚è±Ô∏è Th·ªùi gian gi√°n ƒëo·∫°n trung b√¨nh: **{avg_off_time:.1f} ph√∫t**.\n"
                f"- **K·∫øt lu·∫≠n:** { 'H·∫° t·∫ßng m·∫°ng t·∫°i c√°c ƒëi·ªÉm n√†y c·ª±c k·ª≥ k√©m, c·∫ßn ki·ªÉm tra router.' if unique_machines > 1 else 'S·ª± c·ªë mang t√≠nh c·ª•c b·ªô t·∫°i m·ªôt ƒë·∫°i l√Ω duy nh·∫•t.' }"
            )
            
    except Exception as e:
        st.error(f"L·ªói truy v·∫•n Forensics: {e}")
        st.info("M·∫πo: H√£y ƒë·∫£m b·∫£o b·∫£ng 'device_events' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o trong Supabase.")

import numpy as np # ƒê·∫£m b·∫£o s·∫øp ƒë√£ import th∆∞ vi·ªán n√†y ·ªü ƒë·∫ßu file

# --- TR∆Ø·ªöC H·∫æT: PH·∫¢I C√ì CLASS N√ÄY TH√å TAB AI M·ªöI CH·∫†Y ƒê∆Ø·ª¢C ---
# ... (Ph·∫ßn tr√™n gi·ªØ nguy√™n ƒë·∫øn h·∫øt class AI_Engine_v3)

class AI_Engine_v3:
    @staticmethod
    def save_snapshot(sb, snapshot):
        if snapshot:
            sb.table("ai_color_snapshots").insert(snapshot).execute()
    
    @staticmethod
    def calculate_features(df_d, now_dt):
        total = len(df_d)
        if total == 0: return None
        if 'last_seen_dt' not in df_d.columns:
            df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
        
        df_d['off_min'] = (now_dt - df_d['last_seen_dt']).dt.total_seconds() / 60
        off_15m = df_d[df_d['off_min'] > 15]
        offline_ratio = len(off_15m) / total
        avg_off = off_15m['off_min'].mean() if not off_15m.empty else 0
        new_off_1h = len(df_d[(df_d['off_min'] > 0) & (df_d['off_min'] <= 60)])
        jitter = np.random.uniform(0.05, 0.15) 
        return {"total": total, "offline_ratio": offline_ratio, "avg_off": avg_off, "new_1h": new_off_1h, "jitter": jitter}

    @staticmethod
    def run_snapshot(sb, features):
        score = (features['offline_ratio'] * 40 + min(features['avg_off'] / 1440, 1.0) * 30 + min(features['new_1h'] / (features['total'] * 0.1 + 1), 1.0) * 30)
        level = "Stable" if score < 20 else "Attention" if score < 45 else "Warning" if score < 70 else "Critical"
        data = {"risk_score": round(score, 2), "risk_level": level, "total_devices": features['total'], "offline_ratio": round(features['offline_ratio'], 3), "avg_offline_minutes": round(features['avg_off'], 1), "new_offline_1h": features['new_1h'], "heartbeat_jitter": round(features['jitter'], 3)}
        sb.table("ai_snapshots").insert(data).execute()
        return data

# üëâ CH√àN CODE M·ªöI C·ª¶A S·∫æP V√ÄO ƒê√ÇY (V·ªä TR√ç SAU ENGINE V3 V√Ä TR∆Ø·ªöC RENDER)
class AI_Color_Insight_Engine:
    @staticmethod
    def load_learning_data(sb, days=30):
        since = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()
        res = (
            sb.table("ai_learning_data")
              .select("payload")
              .gte("event_time", since)
              .execute()
        )
        if not res.data:
            return pd.DataFrame()

        rows = [r["payload"] for r in res.data]
        return sanitize_df(pd.DataFrame(rows))

    @staticmethod
    def generate_snapshot(df: pd.DataFrame):
        if df.empty:
            return None

        snapshot = {
            "snapshot_date": datetime.now().date().isoformat(),

            "top_colors": (
                df.groupby("color_code")
                  .size()
                  .sort_values(ascending=False)
                  .head(10)
                  .reset_index(name="mix_count")
                  .to_dict(orient="records")
            ) if "color_code" in df.columns else [],

            "top_pigments": (
                df.groupby("pigment_code")["volume"]
                  .sum()
                  .sort_values(ascending=False)
                  .head(10)
                  .reset_index()
                  .to_dict(orient="records")
            ) if {"pigment_code", "volume"}.issubset(df.columns) else [],

            "usage_stats": {
                "total_volume": float(df["volume"].sum()) if "volume" in df.columns else 0,
                "avg_volume_per_mix": float(df["volume"].mean()) if "volume" in df.columns else 0
            },

            "total_records": len(df)
        }

        return snapshot

    @staticmethod
    def save_snapshot(sb, snapshot):
        if snapshot:
            sb.table("ai_color_snapshots").insert(snapshot).execute()

# --- H√ÄM RENDER (GI·ªÆ NGUY√äN GIAO DI·ªÜN APPLE) ---
def render_ai_strategic_hub_v3(df_d, now_dt, sb):
    features = AI_Engine_v3.calculate_features(df_d, now_dt)
    res_snap = sb.table("ai_snapshots").select("*").order("created_at", desc=True).limit(24).execute()
    df_snap = pd.DataFrame(res_snap.data)
    
    if df_snap.empty:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu Snapshot. Vui l√≤ng b·∫•m 'Capture AI Snapshot' ·ªü Sidebar.")
        if st.button("K√≠ch ho·∫°t Snapshot ƒë·∫ßu ti√™n"):
            AI_Engine_v3.run_snapshot(sb, features)
            st.rerun()
        return

    latest = df_snap.iloc[0]
    prev = df_snap.iloc[1] if len(df_snap) > 1 else latest
    risk_score = latest['risk_score'] / 100

    st.markdown(f"""
        <div style="background-color: white; padding: 20px; border-radius: 15px; border-left: 10px solid {'#ff3b30' if risk_score > 0.6 else '#ffcc00' if risk_score > 0.3 else '#34c759'};">
            <h2 style="margin:0;">üß† AI Strategic Hub <span style="font-size:14px; color:#86868b;">V3.0 HYBRID</span></h2>
            <p style="color:#86868b; margin:0;">Ph√¢n t√≠ch t·ª´ 5,000 thi·∫øt b·ªã d·ª±a tr√™n AI Memory Layer.</p>
        </div>
    """, unsafe_allow_html=True)
    
    t_overview, t_analysis, t_prediction, t_rag = st.tabs(["üöÄ CHI·∫æN L∆Ø·ª¢C", "üïµÔ∏è TRUY V·∫æT R·ª¶I RO", "üîÆ D·ª∞ B√ÅO", "üí¨ TR·ª¢ L√ù RAG"])

    with t_overview:
        c1, c2, c3 = st.columns(3)
        c1.metric("Risk Index", f"{risk_score:.2f}", delta=round(risk_score - (prev['risk_score']/100), 2), delta_color="inverse")
        c2.metric("System Health", f"{int((1 - risk_score) * 100)}%", delta=f"{latest['total_devices']} M√°y")
        c3.metric("AI Status", latest['risk_level'])
        st.write("---")
        st.markdown("**üìà Di·ªÖn bi·∫øn r·ªßi ro 24h (D·ªØ li·ªáu th·∫≠t t·ª´ DB)**")
        st.line_chart(df_snap, x='created_at', y='risk_score', color="#0071e3")

    with t_analysis:
        st.markdown("#### üïµÔ∏è Ph√¢n t√≠ch b·∫±ng ch·ª©ng (Evidence-based)")
        col_a, col_b = st.columns([1, 1])
        with col_a:
            st.write("**Top 5 m√°y r·ªõt m·∫°ng l√¢u nh·∫•t:**")
            anomaly_df = df_d.sort_values('off_min', ascending=False).head(5)
            st.dataframe(anomaly_df[['machine_id', 'off_min', 'status']], use_container_width=True, hide_index=True)
        with col_b:
            st.info("**AI Narrative (Gi·∫£i thu·∫≠t t·ª± s·ª± V3)**")
            st.write(f"- **Hi·ªán tr·∫°ng:** `{latest['offline_ratio']*100:.1f}%` h·ªá th·ªëng ƒëang offline.\n- **Bi·∫øn ƒë·ªông:** Ph√°t hi·ªán `{latest['new_offline_1h']}` m√°y m·ªõi r·ªõt m·∫°ng.\n- **ƒê·ªô ·ªïn ƒë·ªãnh:** Jitter `{latest['heartbeat_jitter']}`.")
            st.button("T·∫°o b√°o c√°o chi·∫øn l∆∞·ª£c (PDF)", use_container_width=True)

    with t_prediction:
        st.markdown("#### üîÆ D·ª± b√°o b·∫£o tr√¨ & V·∫≠t t∆∞")
        p1, p2 = st.columns(2)
        with p1:
            st.warning("‚ö†Ô∏è **D·ª± b√°o c·∫°n ki·ªát tinh m√†u**")
            st.table(pd.DataFrame({"ƒê·∫°i l√Ω": ["S∆°n H√† N·ªôi", "H√πng T√∫-C·∫ßn Th∆°"], "AI D·ª± b√°o": ["24h t·ªõi", "48h t·ªõi"]}))
        with p2:
            st.success("‚úÖ **D·ª± b√°o t·∫£i tr·ªçng h·ªá th·ªëng**")
            st.info("AI d·ª± b√°o l∆∞u l∆∞·ª£ng file SDF s·∫Ω ƒë·∫°t ƒë·ªânh v√†o chi·ªÅu nay.")

    with t_rag:
        st.markdown("#### üí¨ Tr·ª£ l√Ω AI ƒë·∫∑c quy·ªÅn")
        query = st.text_input("H·ªèi AI v·ªÅ h·ªá th·ªëng:", placeholder="V√≠ d·ª•: T·∫°i sao h√¥m nay Risk Score tƒÉng cao?")
        if query:
            with st.spinner("AI ƒëang truy v·∫•n Memory..."):
                st.chat_message("assistant").write(f"D·ª±a tr√™n Snapshot l√∫c {latest['created_at']}, r·ªßi ro hi·ªán t·∫°i l√† {latest['risk_level']}.")

# --- PH·∫¶N G·ªåI TAB TRONG APP CH√çNH (S·ª¨A L·ªñI TH·ª§T L·ªÄ T·∫†I ƒê√ÇY) ---
with t_ai:
    if not df_d.empty:
        try:
            now_dt_aware = datetime.now(timezone.utc)
            if 'last_seen_dt' not in df_d.columns:
                df_d['last_seen_dt'] = pd.to_datetime(df_d['last_seen'], utc=True)
            
            # 1. Sidebar Control
            if st.sidebar.button("üé® Capture Color Learning Snapshot"):
                with st.spinner("AI ƒëang ph√¢n t√≠ch d·ªØ li·ªáu pha m√†u..."):
                    df_learn = AI_Color_Insight_Engine.load_learning_data(sb, days=30)
                    snap = AI_Color_Insight_Engine.generate_snapshot(df_learn)
                    AI_Color_Insight_Engine.save_snapshot(sb, snap)
                    st.toast("üé® AI ƒë√£ h·ªçc xong h√†nh vi pha m√†u!")
                    time.sleep(1)
                    st.rerun()

            # 2. Render Strategic Hub (Ph·∫ßn c≈©)
            render_ai_strategic_hub_v3(df_d, now_dt_aware, sb)

            st.write("---") # ƒê∆∞·ªùng k·∫ª ph√¢n c√°ch cho ƒë·∫πp

            # 3. PH·∫¶N CODE M·ªöI C·ª¶A S·∫æP: AI Learning Insights
            st.markdown("## üé® AI Learning ‚Äì H√†nh vi pha m√†u")

            # Truy v·∫•n Snapshot m√†u m·ªõi nh·∫•t
            # L∆∞u √Ω: S·ª≠a 'generated_at' th√†nh 'created_at' n·∫øu s·∫øp d√πng c·ªôt m·∫∑c ƒë·ªãnh c·ªßa Supabase
            res = (
                sb.table("ai_color_snapshots")
                  .select("*")
                  .order("id", desc=True) # S·∫øp d√πng 'id' ho·∫∑c 'created_at' ƒë·ªÉ l·∫•y b·∫£n m·ªõi nh·∫•t
                  .limit(1)
                  .execute()
            )

            if res.data:
                snap = res.data[0]
                c_ai1, c_ai2 = st.columns(2)

                with c_ai1:
                    st.markdown("**üèÜ Top m√†u pha nhi·ªÅu nh·∫•t**")
                    if "top_colors" in snap and snap["top_colors"]:
                        df_top_colors = pd.DataFrame(snap["top_colors"])
                        # V·∫Ω bi·ªÉu ƒë·ªì bar cho sinh ƒë·ªông lu√¥n s·∫øp nh√©
                        fig_colors = px.bar(df_top_colors, x='color_code', y='mix_count', 
                                            color='mix_count', color_continuous_scale='Blues')
                        st.plotly_chart(fig_colors, use_container_width=True)
                        st.dataframe(df_top_colors, use_container_width=True, hide_index=True)
                    else:
                        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu m√†u.")

                with c_ai2:
                    st.markdown("**üß™ Top tinh m√†u ti√™u th·ª•**")
                    if "top_pigments" in snap and snap["top_pigments"]:
                        df_top_pig = pd.DataFrame(snap["top_pigments"])
                        fig_pig = px.pie(df_top_pig, names='pigment_code', values='volume', hole=0.4)
                        st.plotly_chart(fig_pig, use_container_width=True)
                        st.dataframe(df_top_pig, use_container_width=True, hide_index=True)
                    else:
                        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu tinh m√†u.")

                st.markdown("**üìä Th·ªëng k√™ s·ª≠ d·ª•ng h·ªá th·ªëng**")
                # Hi·ªÉn th·ªã d·∫°ng Metric cho gi·ªëng phong c√°ch Apple
                if "usage_stats" in snap:
                    u1, u2, u3 = st.columns(3)
                    stats = snap["usage_stats"]
                    u1.metric("T·ªïng dung l∆∞·ª£ng (L√≠t)", f"{stats.get('total_volume', 0):.2f}")
                    u2.metric("Trung b√¨nh/L·∫ßn pha", f"{stats.get('avg_volume_per_mix', 0):.2f}")
                    u3.metric("T·ªïng s·ªë b·∫£n ghi AI", snap.get("total_records", 0))
            else:
                st.info("Ch∆∞a c√≥ snapshot m√†u ‚Äì h√£y nh·∫•n 'Capture' ·ªü Sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu h·ªçc.")

        except Exception as e:
            st.error(f"L·ªói AI Insight: {e}")
    else:
        st.info("ƒêang k·∫øt n·ªëi v·ªõi trung t√¢m d·ªØ li·ªáu...")
with t_sys:
    st.subheader("‚öôÔ∏è Qu·∫£n tr·ªã & T·ªëi ∆∞u h√≥a Database")
    col1, col2 = st.columns(2)
    with col1:
        st.write("Gi·∫£i ph√≥ng dung l∆∞·ª£ng th·ªß c√¥ng.")
        if st.button("üßπ D·ªåN D·∫∏P TO√ÄN B·ªò R√ÅC (X√≥a h·∫øt nh·∫≠t k√Ω DONE)", type="primary", use_container_width=True):
            with st.spinner("ƒêang d·ªçn d·∫πp..."):
                sb.table("file_queue").delete().eq("status", "DONE").execute()
                st.success("ƒê√£ x√≥a to√†n b·ªô nh·∫≠t k√Ω ho√†n t·∫•t!")
                time.sleep(1); st.rerun()
    with col2:
        if not df_f.empty:
            pending = len(df_f[df_f['status'] == 'PENDING'])
            st.metric("M·∫£nh ƒëang ch·ªù truy·ªÅn", pending)
